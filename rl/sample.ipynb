{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d8893b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4048a99",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4262247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch, torchrl\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.utils import NestedKey\n",
    "from torch import Tensor\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "from torch.utils.cpp_extension import load_inline\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import (\n",
    "    Binary,\n",
    "    Categorical,\n",
    "    Composite,\n",
    "    LazyTensorStorage,\n",
    "    ReplayBuffer,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuous\n",
    ")\n",
    "from torchrl.data.replay_buffers import SamplerWithoutReplacement\n",
    "from torchrl.envs import EnvBase, SerialEnv\n",
    "from torchrl.envs.transforms import ActionMask, TransformedEnv\n",
    "from torchrl.modules import MaskedCategorical, ProbabilisticActor\n",
    "from torchrl.objectives import SoftUpdate\n",
    "from torchrl.objectives.sac import DiscreteSACLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90e20c",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b431a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# DEVICE = 'cpu' # Device for training\n",
    "BATCH_SIZE = 32 # Batch size for training\n",
    "LR = 1e-4 # Learning rate for the optimizer\n",
    "WEIGHT_DECAY = 1e-4 # Weight decay for the optimizer\n",
    "\n",
    "MAX_BOARD_SIZE = 5 # Maximum board size for the Hex game\n",
    "N_CHANNEL = 4 # Number of channels for the observation (Red, Blue, Playable Mask, Swapable Indicator)\n",
    "BOARD_SIZE = 5 # Size of the Hex board (board_size x board_size)\n",
    "SWAP_RULE = True # Whether to use the swap rule in the Hex game\n",
    "\n",
    "BUFFER_SIZE = 100_000 # Size of the replay buffer\n",
    "N_FRAMES_PER_BATCH = 128 # Number of frames to store in the replay buffer per episode\n",
    "STORAGE_DEVICE = DEVICE  # Device for storing the replay buffer data\n",
    "# STORAGE_DEVICE = 'cpu' # Device for storing the replay buffer data\n",
    "\n",
    "# Training Configuration\n",
    "TOTAL_FRAMES = 1_000_000 # Total training frames\n",
    "WARMUP_FRAMES = 5_000 # Random exploration frames before training\n",
    "OPTIMIZATION_STEPS = 10 # UTD Ratio: gradient updates per collection\n",
    "TAU = 0.005 # Soft update coefficient for target network\n",
    "LOG_INTERVAL = 100 # Log and evaluate every N iterations\n",
    "EVAL_GAMES = 200 # Number of games for evaluation\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"conv_layers\": [(32, 3)],\n",
    "    \"n_encoder_layers\": 1,\n",
    "    \"d_input\": N_CHANNEL,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_ff\": 128,\n",
    "    \"dropout\": 0.01,\n",
    "    \"output_flatten\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f97d6",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfd701",
   "metadata": {},
   "source": [
    "## Base Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7bfea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HexEnv(EnvBase):\n",
    "    \"\"\"Hex game environment for reinforcement learning.\"\"\"\n",
    "    N_ENV_CHANNELS = 5  # Red (P0), Blue (P1), Current Player, Playable Mask, Swapable Indicator\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        board_size: Size of the game board (board_size x board_size)\n",
    "        max_board_size: Maximum board size for padding\n",
    "        swap_rule: Whether to enable the swap rule (default: True)\n",
    "        device: Device for tensor computation (default: 'cpu')\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        board_size: int,\n",
    "        max_board_size: int,\n",
    "        swap_rule: bool = True,\n",
    "        device: torch.device = torch.device('cpu')\n",
    "    ):\n",
    "        # Assertions\n",
    "        assert board_size >= 1, \"Board size must be greater than or equal to 1.\"\n",
    "        assert board_size <= max_board_size, \"Board size must be less than or equal to max Board size.\"\n",
    "\n",
    "        super().__init__(device=device, spec_locked=False)\n",
    "\n",
    "        # Parameters\n",
    "        self.board_size: int = board_size\n",
    "        self.max_board_size: int = max_board_size\n",
    "        self.n_channel: int = self.N_ENV_CHANNELS\n",
    "        self.swap_rule: bool = swap_rule\n",
    "\n",
    "        # Create shape variables\n",
    "        self.board_shape: torch.Size = torch.Size(\n",
    "            (self.max_board_size, self.max_board_size)\n",
    "        ) # (max_board_size, max_board_size)\n",
    "\n",
    "        # Valid board mask\n",
    "        self.valid_board: Tensor = torch.zeros(\n",
    "            self.board_shape, \n",
    "            dtype=torch.bool, \n",
    "            device=self.device\n",
    "        ) # (max_board_size, max_board_size)\n",
    "        self.valid_board[:self.board_size, :self.board_size] = 1\n",
    "\n",
    "        # Create private spec variables\n",
    "        self.observation_spec = Composite({\n",
    "            \"observation\": Binary(\n",
    "                shape=self.board_shape + (self.n_channel,),\n",
    "                # (max_board_size, max_board_size, n_channel)\n",
    "                device=self.device,\n",
    "                dtype=torch.float32\n",
    "            ),\n",
    "            \"action_mask\": Binary(\n",
    "                shape=(self.max_board_size ** 2,),\n",
    "                # (max_board_size ** 2,)\n",
    "                device=self.device,\n",
    "                dtype=torch.bool\n",
    "            )\n",
    "        })\n",
    "        self.action_spec = Categorical(\n",
    "            n=self.max_board_size ** 2,\n",
    "            # Number of discrete actions for each side of the board\n",
    "            device=self.device,\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        self.reward_spec = UnboundedContinuous(\n",
    "            shape=(1,),\n",
    "            device=device,\n",
    "            dtype=torch.float32\n",
    "        ) # Reward for both players\n",
    "\n",
    "    def _reset(self, tensordict: TensorDict | None = None, **kwargs) -> TensorDict:\n",
    "        # Initialize a fresh board\n",
    "        board: Tensor = torch.full((self.max_board_size, self.max_board_size), -1, dtype=torch.long, device=self.device) # -1: empty, 0: player 0 (red), 1: player 1 (blue)\n",
    "        current_player: int = 0 # 0: player 0 (red), 1: player 1 (blue)\n",
    "        done: Tensor = torch.tensor(False, dtype=torch.bool, device=self.device) # Game not done\n",
    "\n",
    "        # Create fresh observation, mask, done, reward\n",
    "        fresh_action: Tensor = torch.tensor([0], dtype=torch.long, device=self.device) # Placeholder action\n",
    "        fresh_observation: Tensor = torch.zeros((self.max_board_size, self.max_board_size, self.n_channel), dtype=torch.float32, device=self.device) # (max_board_size, max_board_size, n_channel)\n",
    "        fresh_observation[..., 0] = (board == 0).float() # Red pieces channel\n",
    "        fresh_observation[..., 1] = (board == 1).float() # Blue pieces channel\n",
    "        fresh_observation[..., 2] = current_player # 0: player 0 (red), 1: player 1 (blue)\n",
    "        fresh_observation[..., 3] = self.valid_board.clone().float() # (max_board_size, max_board_size) Playable board mask\n",
    "        fresh_observation[..., 4] = self.swap_rule * 1.0 # Swap rule indicator channel\n",
    "        fresh_action_mask: Tensor = self.valid_board.clone().bool().flatten() # (max_board_size ** 2,) Valid move mask\n",
    "        fresh_done: Tensor = done # Not done\n",
    "\n",
    "        fresh_tensordict: TensorDict = TensorDict({\n",
    "            \"action\": fresh_action,\n",
    "            \"observation\": fresh_observation,\n",
    "            \"action_mask\": fresh_action_mask,\n",
    "            \"done\": fresh_done\n",
    "        }, device=self.device)\n",
    "        return fresh_tensordict\n",
    "\n",
    "    def _step(self, tensordict: TensorDict, **kwargs) -> TensorDict:\n",
    "        action: Tensor = tensordict.get(\"action\").clone() # Scalar tensor representing the action\n",
    "        observation: Tensor = tensordict.get(\"observation\").clone() # (max_board_size, max_board_size, n_channel)\n",
    "\n",
    "        # Extract action details\n",
    "        index = int(action.item())\n",
    "        row, col = divmod(index, self.max_board_size)\n",
    "\n",
    "        # Extract observation details\n",
    "        current_player = int(observation[0, 0, 2].item())\n",
    "        swap_available = bool(observation[0, 0, 4].item())\n",
    "\n",
    "        board_red, board_blue = observation[..., 0], observation[..., 1]\n",
    "        total_stones = int((board_red + board_blue).sum().item())\n",
    "\n",
    "        if not (0 <= row < self.max_board_size and 0 <= col < self.max_board_size):\n",
    "            raise ValueError(f\"Invalid action {index}: out of bounds (row={row}, col={col}).\")\n",
    "        if not self.valid_board[row, col]:\n",
    "            raise ValueError(f\"Invalid action {index}: outside playable area (row={row}, col={col}).\")\n",
    "    \n",
    "        cell_empty = (board_red[row, col] == 0) and (board_blue[row, col] == 0)\n",
    "        swap_action = (\n",
    "            self.swap_rule\n",
    "            and swap_available\n",
    "            and current_player == 1\n",
    "            and total_stones == 1\n",
    "            and board_red[row, col] == 1\n",
    "            and board_blue[row, col] == 0\n",
    "        ) # Player 1 (blue) can swap only on their first move\n",
    "\n",
    "        if not (cell_empty or swap_action):\n",
    "            raise ValueError(f\"Invalid action {index}: cell occupied and swap not permitted.\")\n",
    "\n",
    "        # Create next observation\n",
    "        next_observation: Tensor = observation.clone()\n",
    "        if swap_action:\n",
    "            next_observation[..., 0], next_observation[..., 1] = next_observation[..., 1].clone(), next_observation[..., 0].clone()\n",
    "        else:\n",
    "            next_observation[row, col, current_player] = 1.0\n",
    "\n",
    "        if self._check_done(next_observation, current_player):\n",
    "            next_reward = torch.tensor([1.0], dtype=torch.float32, device=self.device)\n",
    "            next_done = torch.tensor(True, dtype=torch.bool, device=self.device)\n",
    "        else:\n",
    "            next_reward = torch.tensor([0.0], dtype=torch.float32, device=self.device)\n",
    "            next_done = torch.tensor(False, dtype=torch.bool, device=self.device)\n",
    "            current_player = 1 - current_player\n",
    "\n",
    "        swap_available_next = bool(self.swap_rule and (total_stones == 0) and not next_done) # Update swap availability for next state\n",
    "        next_observation[..., 2] = float(current_player)\n",
    "        next_observation[..., 4] = float(swap_available_next)\n",
    "\n",
    "        empty_mask = (next_observation[..., 0] == 0) & (next_observation[..., 1] == 0) & self.valid_board\n",
    "        next_action_mask = empty_mask.flatten()\n",
    "        if swap_available_next:\n",
    "            next_action_mask[index] = True\n",
    "\n",
    "        next_tensordict: TensorDict = TensorDict({\n",
    "            \"observation\": next_observation,\n",
    "            \"action_mask\": next_action_mask,\n",
    "            \"done\": next_done,\n",
    "            \"reward\": next_reward\n",
    "        }, device=self.device)\n",
    "        return next_tensordict\n",
    "\n",
    "    def _check_done(self, observation: Tensor, current_player: int) -> bool:\n",
    "        def dfs(board, start_positions, target_condition, directions):\n",
    "            visited = torch.zeros((self.board_size, self.board_size), dtype=torch.bool)\n",
    "            for start in start_positions:\n",
    "                if board[start] == 1 and not visited[start]:\n",
    "                    stack = [start]\n",
    "                    visited[start] = True\n",
    "                    while stack:\n",
    "                        r, c = stack.pop()\n",
    "                        if target_condition(r, c):\n",
    "                            return True\n",
    "                        for dr, dc in directions:\n",
    "                            nr, nc = r + dr, c + dc\n",
    "                            if 0 <= nr < self.board_size and 0 <= nc < self.board_size and board[nr, nc] == 1 and not visited[nr, nc]:\n",
    "                                visited[nr, nc] = True\n",
    "                                stack.append((nr, nc))\n",
    "            return False\n",
    "\n",
    "        directions = [(-1,0), (1,0), (0,-1), (0,1), (1,-1), (-1,1)] # 6 possible directions in a hex grid\n",
    "        board_state = observation[:self.board_size, :self.board_size, :]\n",
    "        # Use DFS to check if player 0 (red) has connected top to bottom\n",
    "        if current_player == 0:\n",
    "            board = board_state[..., 0] # Shape (board_size, board_size) # Player 0 pieces\n",
    "            start_positions = [(0, col) for col in range(self.board_size)]\n",
    "            target_condition = lambda r, c: r == self.board_size - 1\n",
    "            if dfs(board, start_positions, target_condition, directions):\n",
    "                return True\n",
    "\n",
    "        # Use DFS to check if player 1 (blue) has connected left to right\n",
    "        else:\n",
    "            board = board_state[..., 1] # Shape (board_size, board_size) # Player 1 pieces\n",
    "            start_positions = [(row, 0) for row in range(self.board_size)]\n",
    "            target_condition = lambda r, c: c == self.board_size - 1\n",
    "            if dfs(board, start_positions, target_condition, directions):\n",
    "                return True\n",
    "\n",
    "        return False # No winner yet\n",
    "\n",
    "    def _set_seed(self, seed: int) -> None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92b169",
   "metadata": {},
   "source": [
    "[0,0] [0,1] [0,2] [0,3]  ← Player 0 bắt đầu\n",
    "  [1,0] [1,1] [1,2] [1,3]\n",
    "    [2,0] [2,1] [2,2] [2,3]\n",
    "      [3,0] [3,1] [3,2] [3,3]  ← Player 0 kết thúc\n",
    "        ↑                      ↑\n",
    "    Player 1                Player 1\n",
    "    bắt đầu               kết thúc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456c9401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0906b725",
   "metadata": {},
   "source": [
    "## Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec1a9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17, 19,  6, 18, 10,  4,  0,  2, 23, 22,  7, 11, 21, 15,  8, 16, 13,  1,\n",
       "         12,  9,  5,  2,  8, 22, 12, 15,  0, 16,  5, 20, 24,  1, 17, 11,  6, 14,\n",
       "          3,  4, 10, 13,  9, 19,  7, 11, 22,  6, 24,  2, 17, 14, 16, 13, 18, 21,\n",
       "          1, 15,  5, 10,  9,  4, 19,  8,  3,  7, 12, 20,  0,  7, 24,  1,  2,  3,\n",
       "         23,  8, 21, 17,  9, 16, 20, 18,  5, 19, 11, 15, 20,  3, 10, 22, 18,  1,\n",
       "         14,  7,  2,  0, 19, 15, 21, 17, 11, 23]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_hex_env = lambda: HexEnv(board_size=BOARD_SIZE, max_board_size=MAX_BOARD_SIZE, swap_rule=SWAP_RULE, device=STORAGE_DEVICE)\n",
    "serial_env = TransformedEnv(\n",
    "    SerialEnv(\n",
    "        num_workers=1,\n",
    "        create_env_fn=create_hex_env\n",
    "    ),\n",
    "    ActionMask()\n",
    ")\n",
    "# serial_env = TransformedEnv(\n",
    "#     HexEnv(\n",
    "#         board_size=BOARD_SIZE,\n",
    "#         max_board_size=MAX_BOARD_SIZE,\n",
    "#         device=STORAGE_DEVICE\n",
    "#     ),\n",
    "#     ActionMask()\n",
    "# )\n",
    "\n",
    "r = serial_env.rollout(100, break_when_any_done=False)\n",
    "r[\"action\"].to(dtype=torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822f2b6",
   "metadata": {},
   "source": [
    "# Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4739e97",
   "metadata": {},
   "source": [
    "## Custom Sub-modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2bb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HexConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size: int = 3, bias: bool = True):\n",
    "        super(HexConv2d, self).__init__()\n",
    "        assert kernel_size % 2 == 1 and kernel_size > 0, \"kernel_size must be odd and positive.\"\n",
    "\n",
    "        stride, padding = 1, kernel_size // 2  # To maintain spatial dimensions\n",
    "        mask = self._create_hex_mask(kernel_size)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
    "        self.register_buffer('mask', mask) # (k, k), requires_grad=False to keep it fixed\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_hex_mask(kernel_size: int) -> Tensor:\n",
    "        assert kernel_size % 2 == 1 and kernel_size > 0, \"kernel_size must be odd and positive.\"\n",
    "\n",
    "        mask = torch.zeros((kernel_size, kernel_size), dtype=torch.float32)\n",
    "        center = kernel_size // 2\n",
    "\n",
    "        for r in range(kernel_size): # Row index\n",
    "            for c in range(kernel_size): # Column index\n",
    "                # Using axial distance for a vertically oriented hex grid\n",
    "                # mapped to an offset coordinate system in the kernel.\n",
    "                # (r, c) are kernel indices, (dr, dc) are relative to center.\n",
    "                dr, dc = r - center, c - center\n",
    "                chebyshev_distance = max(abs(dr), abs(dc), abs(dr + dc))\n",
    "\n",
    "                if chebyshev_distance <= center: # Inside or on the hexagon\n",
    "                    mask[r, c] = 1.0\n",
    "\n",
    "        return mask # (kernel_size, kernel_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # 1. Tạo trọng số đã mask (Soft masking)\n",
    "        # Phép nhân '*' tạo ra tensor mới, KHÔNG sửa in-place trọng số gốc.\n",
    "        # Gradient vẫn truyền ngược qua đây bình thường, các vị trí mask=0 sẽ có grad=0.\n",
    "        masked_weight = self.conv.weight * self.mask\n",
    "        \n",
    "        # 2. Dùng functional conv2d thay vì self.conv(x)\n",
    "        # Chúng ta truyền masked_weight vào đây.\n",
    "        x = F.conv2d(\n",
    "            input=x,\n",
    "            weight=masked_weight,\n",
    "            bias=self.conv.bias,\n",
    "            stride=self.conv.stride,\n",
    "            padding=self.conv.padding,\n",
    "            dilation=self.conv.dilation,\n",
    "            groups=self.conv.groups\n",
    "        )\n",
    "        return x\n",
    "\n",
    "\n",
    "class SkipConnection(nn.Module):\n",
    "    def __init__(self, adjust_input: nn.Module, original_input: nn.Module = nn.Identity()):\n",
    "        super(SkipConnection, self).__init__()\n",
    "        self.adjust_input = adjust_input\n",
    "        self.original_input = original_input\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.adjust_input(x) + self.original_input(x)\n",
    "\n",
    "\n",
    "class TriAxialPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model: Kích thước channel của input (C). Phải là số chẵn.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert d_model % 2 == 0, \"d_model (C) phải là số chẵn để tính sin/cos.\"\n",
    "\n",
    "        # Pre-compute div_term cho sinusoidal\n",
    "        # Lưu ý: arange(0, d_model, 2) tạo ra d_model/2 phần tử\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.register_buffer('div_term', div_term)\n",
    "\n",
    "    def _get_1d_sinusoidal(self, coords: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Tạo sinusoidal embedding cho một trục toạ độ.\n",
    "        Args:\n",
    "            coords: Tensor chứa giá trị toạ độ (số nguyên hoặc thực), shape (H, W)\n",
    "        Returns:\n",
    "            Tensor embedding, shape (H, W, d_model)\n",
    "        \"\"\"\n",
    "        # Mở rộng chiều cuối để tính toán: (H, W, 1)\n",
    "        coords = coords.unsqueeze(-1).float()\n",
    "        \n",
    "        # div_term có shape (d_model/2,)\n",
    "        # phase = coords * div_term -> Shape (H, W, d_model/2)\n",
    "        phase = coords * self.div_term\n",
    "        \n",
    "        # Tính sin và cos riêng biệt\n",
    "        sin_part = torch.sin(phase) # (H, W, d_model/2)\n",
    "        cos_part = torch.cos(phase) # (H, W, d_model/2)\n",
    "        \n",
    "        # --- FIX LỖI VMAP Ở ĐÂY ---\n",
    "        # Thay vì gán in-place (pe[..., 0::2] = ...), ta dùng stack và flatten.\n",
    "        # 1. Stack lại ở chiều cuối cùng: (H, W, d_model/2, 2)\n",
    "        #    Tại vị trí cuối: [sin, cos], [sin, cos], ...\n",
    "        val = torch.stack([sin_part, cos_part], dim=-1)\n",
    "        \n",
    "        # 2. Flatten 2 chiều cuối để trộn lại thành (H, W, d_model)\n",
    "        #    Kết quả sẽ là: sin, cos, sin, cos... đúng thứ tự chẵn lẻ\n",
    "        pe = val.flatten(-2, -1)\n",
    "        \n",
    "        return pe\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # ... (Giữ nguyên phần logic forward cũ) ...\n",
    "        N, H, W, C = x.shape\n",
    "        assert C == self.d_model, f\"Input channel {C} không khớp với d_model khởi tạo {self.d_model}\"\n",
    "\n",
    "        device = x.device\n",
    "\n",
    "        rows = torch.arange(H, device=device, dtype=torch.float)\n",
    "        cols = torch.arange(W, device=device, dtype=torch.float)\n",
    "        \n",
    "        r_grid, q_grid = torch.meshgrid(rows, cols, indexing='ij')\n",
    "\n",
    "        s_grid = -q_grid - r_grid\n",
    "\n",
    "        pe_q = self._get_1d_sinusoidal(q_grid)\n",
    "        pe_r = self._get_1d_sinusoidal(r_grid)\n",
    "        pe_s = self._get_1d_sinusoidal(s_grid)\n",
    "\n",
    "        full_pe = (pe_q + pe_r + pe_s) / math.sqrt(3)\n",
    "\n",
    "        return full_pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c3b06",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc416374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HexModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 conv_layers: list[tuple[int, int]],\n",
    "                 n_encoder_layers: int,\n",
    "                 d_input: int,\n",
    "                 n_heads: int = 8,\n",
    "                 d_ff: int = 2048,\n",
    "                 dropout: float = 0.1,\n",
    "                 output_flatten: bool = True):\n",
    "        \"\"\"Args:\n",
    "            conv_layers: List of tuples (out_channels, kernel_size) for each conv layer.\n",
    "                Note that, in_channels is inferred from the previous layer's out_channels (d_input for the first layer).\n",
    "            n_encoder_layers: Number of transformer encoder layers.\n",
    "            d_input: Dimension of input features to the transformer.\n",
    "            n_heads: Number of attention heads in the transformer.\n",
    "            d_ff: Dimension of the feedforward network in the transformer.\n",
    "            dropout: Dropout rate.\n",
    "        \"\"\"\n",
    "        super(HexModel, self).__init__()\n",
    "        self.output_flatten = output_flatten\n",
    "        self.d_encoder: int = conv_layers[-1][0] # Last conv layer's out_channels as d_model\n",
    "        self.conv = nn.Sequential(*[\n",
    "            SkipConnection(\n",
    "                nn.Sequential(\n",
    "                    HexConv2d(conv_layers[i-1][0] if i > 0 else d_input, conv_layers[i][0], conv_layers[i][1], bias=False),\n",
    "                    nn.GroupNorm(num_groups=4, num_channels=conv_layers[i][0]),\n",
    "                    nn.GELU(),\n",
    "                    HexConv2d(conv_layers[i][0], conv_layers[i][0], conv_layers[i][1], bias=False),\n",
    "                    nn.GroupNorm(num_groups=4, num_channels=conv_layers[i][0]),\n",
    "                ),\n",
    "                nn.Identity() if (i > 0 and conv_layers[i][0] == conv_layers[i-1][0]) # Skip connection (identity)\n",
    "                else nn.Sequential(\n",
    "                    nn.Conv2d(conv_layers[i-1][0] if i > 0 else d_input, conv_layers[i][0], 1), # Combine with Conv2d (kernel_size = 1) for channel adjustment\n",
    "                    nn.GroupNorm(num_groups=4, num_channels=conv_layers[i][0]),\n",
    "                )\n",
    "            )\n",
    "            for i in range(len(conv_layers))\n",
    "        ])\n",
    "        self.positional_embedding = TriAxialPositionalEmbedding(self.d_encoder)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=self.d_encoder,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=d_ff,\n",
    "                dropout=dropout,\n",
    "                activation='gelu',\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=n_encoder_layers\n",
    "        )\n",
    "        self.projection = nn.Linear(self.d_encoder, 1) # Đầu ra cho Actor (logits)/Critic (Q-value)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Args:\n",
    "            x: Input tensor of shape (N, H, W, C) where\n",
    "               N = batch size, H = height, W = width, C = channels (d_input).\n",
    "            Returns: Tensor of shape (N, H, W) with Q-values for each position.\n",
    "        \"\"\"\n",
    "        # Reshape input to (N, C, H, W) for Conv2d\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)  # Add batch dimension if missing\n",
    "        elif len(x.shape) != 4:\n",
    "            raise ValueError(f\"Input tensor x must have shape (N, H, W, C) or (H, W, C), but got {x.shape}.\")\n",
    "\n",
    "        # 1. Convolutional layers\n",
    "        batch_size, height, width = x.size(0), x.size(1), x.size(2)\n",
    "        x = x.permute(0, 3, 1, 2).contiguous() # (N, C, H, W)\n",
    "        x = self.conv(x) # (N, d_encoder, H, W)\n",
    "\n",
    "        # 2. Positional Embedding + Transformer Encoder\n",
    "        # x = x.permute(0, 2, 3, 1).flatten(1, 2).contiguous()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        pe: Tensor = self.positional_embedding(x)\n",
    "        x = (x + pe).flatten(1, 2).contiguous() # (N, H*W, d_encoder)\n",
    "        x = self.encoder(x) # (N, H*W, d_encoder)\n",
    "\n",
    "        # Chỉ sử dụng khi sử dụng vmap của DiscreteSACLOss (deactivate_vmap=False)\n",
    "        # Nếu không dùng vmap thì không cần thiết (do giảm hiệu suất).\n",
    "        # with sdpa_kernel(SDPBackend.MATH):\n",
    "        #     x = self.encoder(x) # (N, H*W, d_encoder)\n",
    "\n",
    "        # 3. Projection to create outputs for Actor/Critic\n",
    "        x = self.projection(x) # (N, H*W, 1)\n",
    "        if self.output_flatten:\n",
    "            return x.squeeze(-1) # (N, H*W)\n",
    "        else:\n",
    "            return x.reshape(batch_size, height, width) # (N, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307f84e",
   "metadata": {},
   "source": [
    "## Policy Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "731454aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Bọc HexModel (Actor).\n",
    "    - Input: 5 channels (Red, Blue, Current Player, Mask, Swap)\n",
    "    - Process: \n",
    "        1. Xác định Player.\n",
    "        2. Nếu là P1: Xoay bàn cờ, Swap Red/Blue.\n",
    "        3. Loại bỏ kênh Current Player -> Còn 4 channels.\n",
    "        4. Chạy Model.\n",
    "        5. Nếu là P1: Xoay ngược Logits output.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: HexModel):\n",
    "        super().__init__()\n",
    "        self.model = model # Tham chiếu đến model chung\n",
    "\n",
    "    def forward(self, observation: Tensor, action_mask: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        # 0. Lấy kích thước và kiểm tra kênh đầu vào\n",
    "        batch_size, _, _, n_channels = observation.shape\n",
    "        assert n_channels == 5, f\"Observation channel phải là 5 (Red, Blue, Current Player, Mask, Swap), nhưng nhận được {n_channels}.\"\n",
    "\n",
    "        # 1. Xác định Player 1\n",
    "        player_mask = observation[..., 0, 0, 2].bool() # Lấy kênh Current Player ở vị trí (0,0) của mỗi board trong batch (N,)\n",
    "        observation = observation[..., [0, 1, 3, 4]].clone() # Loại bỏ kênh Current Player, giữ lại (Red, Blue, Mask, Swap) (N, H, W, 4)\n",
    "\n",
    "        # 2. Tạo input 4 kênh cho model\n",
    "        if player_mask.any(): # Có Player 1 trong batch\n",
    "            observation[player_mask] = observation[player_mask].transpose(1, 2) # Xoay board cho Player 1\n",
    "            observation[player_mask, ..., 0], observation[player_mask, ..., 1] = (\n",
    "                observation[player_mask, ..., 1].clone(), \n",
    "                observation[player_mask, ..., 0].clone()\n",
    "            ) # Swap Red/Blue cho Player 1\n",
    "\n",
    "        # 3. Chạy model chung, chỉ lấy đầu ra đầu tiên\n",
    "        logits = self.model(observation) # logits shape (N, H, W)\n",
    "\n",
    "        # 4. Xoay ngược logits cho Player 1\n",
    "        if player_mask.any(): # Có Player 1 trong batch\n",
    "            logits[player_mask] = logits[player_mask].transpose(1, 2) # Xoay ngược lại\n",
    "        logits = logits.view(batch_size, -1) # (N, H*W)\n",
    "\n",
    "        # 5. Xử lý action_mask\n",
    "        action_mask = action_mask.view(batch_size, -1) # (N, H*W)\n",
    "        # logits[~action_mask] = -torch.inf # Áp dụng mask\n",
    "\n",
    "        return logits, action_mask\n",
    "\n",
    "\n",
    "class CriticWrapper(nn.Module):\n",
    "    \"\"\"Bọc HexModel, chỉ trả về 'action_value'.\"\"\"\n",
    "    def __init__(self, model: HexModel):\n",
    "        super().__init__()\n",
    "        self.model = model # Tham chiếu đến CÙNG model chung\n",
    "\n",
    "    def forward(self, observation: Tensor) -> Tensor:\n",
    "        # 0. Lấy kích thước và kiểm tra kênh đầu vào\n",
    "        batch_size, _, _, n_channels = observation.shape\n",
    "        assert n_channels == 5, f\"Observation channel phải là 5 (Red, Blue, Current Player, Mask, Swap), nhưng nhận được {n_channels}.\"\n",
    "\n",
    "        # 1. Xác định Player 1\n",
    "        player_mask = observation[..., 0, 0, 2].bool() # Lấy kênh Current Player ở vị trí (0,0) của mỗi board trong batch (N,)\n",
    "        observation = observation[..., [0, 1, 3, 4]].clone() # Loại bỏ kênh Current Player, chỉ giữ (Red, Blue, Mask, Swap) (N, H, W, 4)\n",
    "\n",
    "        # 2. Tạo input 4 kênh cho model\n",
    "        if player_mask.any(): # Có Player 1 trong batch\n",
    "            observation[player_mask] = observation[player_mask].transpose(1, 2) # Xoay board cho Player 1\n",
    "            observation[player_mask, ..., 0], observation[player_mask, ..., 1] = (\n",
    "                observation[player_mask, ..., 1].clone(), \n",
    "                observation[player_mask, ..., 0].clone()\n",
    "            ) # Swap Red/Blue cho Player 1\n",
    "\n",
    "        # 3. Chạy model chung, chỉ lấy đầu ra đầu tiên\n",
    "        q_values = self.model(observation) # logits shape (N, H, W)\n",
    "\n",
    "        # 4. Xoay ngược logits cho Player 1\n",
    "        if player_mask.any(): # Có Player 1 trong batch\n",
    "            q_values[player_mask] = q_values[player_mask].transpose(1, 2) # Xoay ngược lại\n",
    "        q_values = q_values.view(batch_size, -1) # (N, H*W)\n",
    "\n",
    "        # q_values[~action_mask] = -torch.inf # Áp dụng mask\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7695ad0",
   "metadata": {},
   "source": [
    "## Masked Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28264575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedRandomPolicy:\n",
    "    \"\"\"A masked random policy for data collectors.\n",
    "\n",
    "    This policy selects random actions from the set of valid (masked) actions only.\n",
    "    It respects the action_mask in the TensorDict to ensure only legal moves are chosen.\n",
    "\n",
    "    This is useful for:\n",
    "    - Warmup phase in RL training (collecting initial random experiences)\n",
    "    - Baseline evaluation (comparing against random play)\n",
    "    - Opponent behavior in self-play scenarios\n",
    "\n",
    "    Args:\n",
    "        action_spec: TensorSpec object describing the action space.\n",
    "            Must be a Categorical spec that supports action masking.\n",
    "        action_key: Key name for the action in TensorDict (default: \"action\")\n",
    "\n",
    "    Examples:\n",
    "        >>> from tensordict import TensorDict\n",
    "        >>> from torchrl.data import Categorical\n",
    "        >>> import torch\n",
    "        >>> \n",
    "        >>> # Create action spec for a 5x5 board (25 possible actions)\n",
    "        >>> action_spec = Categorical(n=25, device='cpu')\n",
    "        >>> policy = MaskedRandomPolicy(action_spec=action_spec)\n",
    "        >>> \n",
    "        >>> # Create a tensordict with action mask (only positions 0, 5, 10 are valid)\n",
    "        >>> action_mask = torch.zeros(25, dtype=torch.bool)\n",
    "        >>> action_mask[[0, 5, 10]] = True\n",
    "        >>> td = TensorDict({\"action_mask\": action_mask}, batch_size=[])\n",
    "        >>> \n",
    "        >>> # Sample random action from valid positions only\n",
    "        >>> td = policy(td)\n",
    "        >>> print(td[\"action\"])  # Will be 0, 5, or 10\n",
    "        \n",
    "    Note:\n",
    "        - The action_mask must be present in the input TensorDict\n",
    "        - Invalid (masked) actions will never be selected\n",
    "        - This ensures compliance with environment constraints (e.g., empty cells in Hex)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_spec: TensorSpec, action_key: NestedKey = \"action\"):\n",
    "        super().__init__()\n",
    "        self.action_spec = action_spec\n",
    "        self.action_key = action_key\n",
    "\n",
    "    def __call__(self, td: TensorDictBase) -> TensorDictBase:\n",
    "        \"\"\"Select a random valid action based on the action mask.\n",
    "        \n",
    "        Args:\n",
    "            td: TensorDict containing at minimum:\n",
    "                - \"action_mask\": Boolean tensor indicating valid actions\n",
    "                \n",
    "        Returns:\n",
    "            TensorDict with added \"action\" key containing the selected action\n",
    "        \"\"\"\n",
    "        action_mask: Tensor = td.get(\"action_mask\")\n",
    "        self.action_spec.update_mask(action_mask)\n",
    "        if isinstance(self.action_spec, Composite):\n",
    "            return td.update(self.action_spec.rand())\n",
    "        else:\n",
    "            return td.set(self.action_key, self.action_spec.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbb53f",
   "metadata": {},
   "source": [
    "# Loss Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e01e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegamaxDiscreteSACLoss(DiscreteSACLoss):\n",
    "    def _compute_target(self, tensordict) -> Tensor:\n",
    "        r\"\"\"Value network for SAC v2.\n",
    "\n",
    "        SAC v2 is based on a value estimate of the form:\n",
    "\n",
    "        .. math::\n",
    "\n",
    "          V = Q(s,a) - \\alpha * \\log p(a | s)\n",
    "\n",
    "        This class computes this value given the actor and qvalue network\n",
    "\n",
    "        \"\"\"\n",
    "        tensordict = tensordict.clone(False)\n",
    "        # get actions and log-probs\n",
    "        with torch.no_grad():\n",
    "            next_tensordict = tensordict.get(\"next\").clone(False)\n",
    "\n",
    "            if self.skip_done_states:\n",
    "                done = next_tensordict.get(self.tensor_keys.done)\n",
    "                if done is not None and done.any():\n",
    "                    next_tensordict_select = next_tensordict[~done.squeeze(-1)]\n",
    "                else:\n",
    "                    next_tensordict_select = next_tensordict\n",
    "\n",
    "                # get probs and log probs for actions computed from \"next\"\n",
    "                with self.actor_network_params.to_module(self.actor_network):\n",
    "                    next_dist = self.actor_network.get_dist(next_tensordict_select)\n",
    "                next_prob = next_dist.probs\n",
    "                next_log_prob = torch.log(torch.where(next_prob == 0, 1e-8, next_prob))\n",
    "\n",
    "                # get q-values for all actions\n",
    "                next_tensordict_expand = self._vmap_qnetworkN0(\n",
    "                    next_tensordict_select, self.target_qvalue_network_params\n",
    "                )\n",
    "                next_action_value = next_tensordict_expand.get(\n",
    "                    self.tensor_keys.action_value\n",
    "                )\n",
    "\n",
    "                # like in continuous SAC, we take the minimum of the value ensemble and subtract the entropy term\n",
    "                next_state_value = (\n",
    "                    next_action_value.min(0)[0] - self._alpha * next_log_prob\n",
    "                )\n",
    "                # unlike in continuous SAC, we can compute the exact expectation over all discrete actions\n",
    "                next_state_value = (next_prob * next_state_value).sum(-1).unsqueeze(-1)\n",
    "                if next_tensordict_select is not next_tensordict:\n",
    "                    mask = ~done\n",
    "                    next_state_value = next_state_value.new_zeros(\n",
    "                        mask.shape\n",
    "                    ).masked_scatter_(mask, next_state_value)\n",
    "            else:\n",
    "                # get probs and log probs for actions computed from \"next\"\n",
    "                with self.actor_network_params.to_module(self.actor_network):\n",
    "                    next_dist = self.actor_network.get_dist(next_tensordict)\n",
    "                next_prob = next_dist.probs\n",
    "                next_log_prob = torch.log(torch.where(next_prob == 0, 1e-8, next_prob))\n",
    "\n",
    "                # get q-values for all actions\n",
    "                next_tensordict_expand = self._vmap_qnetworkN0(\n",
    "                    next_tensordict, self.target_qvalue_network_params\n",
    "                )\n",
    "                next_action_value = next_tensordict_expand.get(\n",
    "                    self.tensor_keys.action_value\n",
    "                )\n",
    "                # like in continuous SAC, we take the minimum of the value ensemble and subtract the entropy term\n",
    "                next_state_value = (\n",
    "                    next_action_value.min(0)[0] - self._alpha * next_log_prob\n",
    "                )\n",
    "                # unlike in continuous SAC, we can compute the exact expectation over all discrete actions\n",
    "                next_state_value = (next_prob * next_state_value).sum(-1).unsqueeze(-1)\n",
    "\n",
    "            next_state_value = -next_state_value  # Negamax adjustment\n",
    "            tensordict.set(\n",
    "                (\"next\", self.value_estimator.tensor_keys.value), next_state_value\n",
    "            )\n",
    "            target_value = self.value_estimator.value_estimate(tensordict).squeeze(-1)\n",
    "            return target_value\n",
    "\n",
    "    def _actor_loss(\n",
    "        self, tensordict: TensorDictBase\n",
    "    ) -> tuple[Tensor, dict[str, Tensor]]:\n",
    "        # get probs and log probs for actions\n",
    "        with self.actor_network_params.to_module(self.actor_network):\n",
    "            dist = self.actor_network.get_dist(tensordict.clone(False))\n",
    "        prob = dist.probs\n",
    "        log_prob = torch.log(torch.where(prob == 0, 1e-8, prob))\n",
    "\n",
    "        td_q = tensordict.select(*self.qvalue_network.in_keys, strict=False)\n",
    "\n",
    "        td_q = self._vmap_qnetworkN0(\n",
    "            td_q, self._cached_detached_qvalue_params  # should we clone?\n",
    "        )\n",
    "        min_q = td_q.get(self.tensor_keys.action_value).min(0)[0]\n",
    "\n",
    "        if log_prob.shape != min_q.shape:\n",
    "            raise RuntimeError(\n",
    "                f\"Losses shape mismatch: {log_prob.shape} and {min_q.shape}\"\n",
    "            )\n",
    "\n",
    "        # like in continuous SAC, we take the entropy term and subtract the minimum of the value ensemble\n",
    "        loss = self._alpha * log_prob - min_q\n",
    "        # unlike in continuous SAC, we can compute the exact expectation over all discrete actions\n",
    "        loss = (prob * loss).sum(-1)\n",
    "\n",
    "        return loss, {\"log_prob\": (log_prob * prob).sum(-1).detach()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdddfd46",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd3337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hàm khởi tạo tham số tối ưu\n",
    "def init_params(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Biến thể của Discrete SAC cho Zero-sum games (như Hex).\n",
    "    Sử dụng cơ chế Negamax: Target = Reward - Gamma * V(next_state).\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Khởi tạo tham số (Weights Initialization) tối ưu cho RL & GELU.\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        # 1. Xử lý Linear và Conv2d (bao gồm cả trong HexConv2d)\n",
    "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "            # Nếu là lớp Projection cuối cùng: Init nhỏ để Policy bắt đầu ngẫu nhiên (Max Entropy)\n",
    "            if hasattr(model, 'projection') and m is model.projection:\n",
    "                nn.init.orthogonal_(m.weight, gain=0.01)\n",
    "            # Các lớp ẩn: Gain = sqrt(2) phù hợp với GELU/ReLU\n",
    "            else:\n",
    "                nn.init.orthogonal_(m.weight, gain=math.sqrt(2))\n",
    "            \n",
    "            # Luôn đưa bias về 0\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "        # 2. Xử lý Normalization (GroupNorm, LayerNorm)\n",
    "        elif isinstance(m, (nn.GroupNorm, nn.LayerNorm, nn.BatchNorm2d)):\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0) # Gamma = 1\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0.0)   # Beta = 0\n",
    "\n",
    "def get_optimizer_params(model: nn.Module, weight_decay: float = 1e-5):\n",
    "    \"\"\"\n",
    "    Tạo dictionary tham số cho AdamW, tách biệt nhóm cần decay và nhóm không.\n",
    "    Args:\n",
    "        weight_decay: Hệ số weight decay mong muốn.\n",
    "    Returns:\n",
    "        List các dict config cho optimizer.\n",
    "    \"\"\"\n",
    "    decay_params = []\n",
    "    no_decay_params = []\n",
    "    \n",
    "    # Danh sách các lớp mà weight của nó CẦN decay\n",
    "    whitelist_weight_modules = (nn.Linear, nn.Conv2d)\n",
    "    # Danh sách các lớp mà weight của nó KHÔNG decay (Norm layers)\n",
    "    blacklist_weight_modules = (nn.GroupNorm, nn.LayerNorm, nn.BatchNorm2d)\n",
    "\n",
    "    # Duyệt qua tất cả module con\n",
    "    for mn, m in model.named_modules():\n",
    "        for pn, p in m.named_parameters(recurse=False):\n",
    "            # Chỉ xét tham số cần học (Mask và Buffer đã tự động bị loại vì requires_grad=False)\n",
    "            if not p.requires_grad:\n",
    "                continue\n",
    "            \n",
    "            full_param_name = f\"{mn}.{pn}\" if mn else pn\n",
    "\n",
    "            # 1. Tất cả Bias -> KHÔNG decay\n",
    "            if pn.endswith('bias'):\n",
    "                no_decay_params.append(p)\n",
    "            \n",
    "            # 2. Weight của Conv/Linear -> CÓ decay\n",
    "            elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                decay_params.append(p)\n",
    "            \n",
    "            # 3. Weight của Norm (Gamma) -> KHÔNG decay\n",
    "            elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                no_decay_params.append(p)\n",
    "            \n",
    "            # 4. Các trường hợp khác (nếu có) -> Mặc định KHÔNG decay cho an toàn\n",
    "            else:\n",
    "                no_decay_params.append(p)\n",
    "\n",
    "    # Kiểm tra nhanh để đảm bảo không bỏ sót tham số nào\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters() if p.requires_grad}\n",
    "    inter_params = len(decay_params) + len(no_decay_params)\n",
    "    assert len(param_dict.keys()) == inter_params, f\"Lỗi: Tổng tham số lọc được ({inter_params}) không khớp với model ({len(param_dict.keys())})\"\n",
    "\n",
    "    return [\n",
    "        {'params': decay_params, 'weight_decay': weight_decay},\n",
    "        {'params': no_decay_params, 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "def merge_optimizer_params(loss_fn_params, actor_groups: list, qvalue_groups: list):\n",
    "    \"\"\"\n",
    "    Gộp các nhóm tham số lại với nhau, loại bỏ trùng lặp theo thứ tự ưu tiên.\n",
    "    \n",
    "    Priority:\n",
    "    1. Actor Groups (Custom weight decay logic)\n",
    "    2. QValue Groups (Custom weight decay logic)\n",
    "    3. Loss Module Leftovers (Ví dụ: log_alpha trong SAC, thường không có weight decay)\n",
    "    \n",
    "    Args:\n",
    "        loss_fn_params: Iterable (thường là loss_fn.parameters())\n",
    "        actor_groups: List dicts từ actor_model.get_optimizer_params()\n",
    "        qvalue_groups: List dicts từ qvalue_model.get_optimizer_params()\n",
    "        \n",
    "    Returns:\n",
    "        List các dict config cho optimizer.\n",
    "    \"\"\"\n",
    "    final_groups = []\n",
    "    seen_param_ids = set()\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1. Ưu tiên cao nhất: Actor Model\n",
    "    # -------------------------------------------------------\n",
    "    for group in actor_groups:\n",
    "        # Lọc những param đã tồn tại (trường hợp hiếm nếu actor/critic share weights)\n",
    "        params = group['params']\n",
    "        new_params = []\n",
    "        for p in params:\n",
    "            if id(p) not in seen_param_ids:\n",
    "                seen_param_ids.add(id(p))\n",
    "                new_params.append(p)\n",
    "        \n",
    "        if new_params:\n",
    "            # Tạo bản copy của group để không sửa đổi input gốc\n",
    "            new_group = group.copy()\n",
    "            new_group['params'] = new_params\n",
    "            final_groups.append(new_group)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2. Ưu tiên nhì: QValue Model\n",
    "    # -------------------------------------------------------\n",
    "    for group in qvalue_groups:\n",
    "        params = group['params']\n",
    "        new_params = []\n",
    "        for p in params:\n",
    "            # Chỉ lấy tham số chưa xuất hiện trong Actor\n",
    "            if id(p) not in seen_param_ids:\n",
    "                seen_param_ids.add(id(p))\n",
    "                new_params.append(p)\n",
    "        \n",
    "        if new_params:\n",
    "            new_group = group.copy()\n",
    "            new_group['params'] = new_params\n",
    "            final_groups.append(new_group)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 3. Ưu tiên thấp nhất: Loss Module (Leftovers)\n",
    "    # (Nơi chứa log_alpha hoặc các tham số tự động của TorchRL)\n",
    "    # -------------------------------------------------------\n",
    "    leftover_params = []\n",
    "    for p in loss_fn_params:\n",
    "        if id(p) not in seen_param_ids:\n",
    "            leftover_params.append(p)\n",
    "            seen_param_ids.add(id(p))\n",
    "    \n",
    "    if leftover_params:\n",
    "        # Các tham số \"thừa\" này thường là hệ số học (như alpha), \n",
    "        # không nên áp dụng weight decay cho chúng.\n",
    "        final_groups.append({\n",
    "            'params': leftover_params, \n",
    "            'weight_decay': 0.0 \n",
    "        })\n",
    "\n",
    "    return final_groups\n",
    "\n",
    "def check_params_changed(model, model_name, old_params):\n",
    "    changed = False\n",
    "    print(f\"Checking updates for {model_name}...\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # Lấy tham số cũ tương ứng\n",
    "            old_p = old_params[name]\n",
    "            # Tính sự khác biệt (norm của hiệu)\n",
    "            diff = (param - old_p).abs().sum().item()\n",
    "            \n",
    "            if diff > 0:\n",
    "                changed = True\n",
    "                # Chỉ in ra một vài layer đại diện để không làm rối màn hình\n",
    "                if \"weight\" in name and diff > 1e-6: \n",
    "                    print(f\"  ✓ {name} changed (diff: {diff:.6f})\")\n",
    "            else:\n",
    "                 print(f\"  ⚠️ {name} did NOT change (diff: 0.0)\")\n",
    "    \n",
    "    if changed:\n",
    "        print(f\"✅ {model_name} weights updated successfully.\")\n",
    "    else:\n",
    "        print(f\"❌ {model_name} weights did NOT update. Check gradients or learning rate.\")\n",
    "    return changed\n",
    "\n",
    "def evaluate_agent(actor: ProbabilisticActor, env: EnvBase, n_games: int = 50, device: str = DEVICE) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate actor against random policy.\n",
    "    \n",
    "    Args:\n",
    "        actor: The actor network to evaluate\n",
    "        env: The environment\n",
    "        n_games: Number of games to play (half as P0, half as P1)\n",
    "        device: Device for computation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with win statistics\n",
    "    \"\"\"\n",
    "    # actor.eval()    \n",
    "    wins_as_p0 = 0\n",
    "    wins_as_p1 = 0\n",
    "    games_as_p0 = n_games // 2\n",
    "    games_as_p1 = n_games - games_as_p0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Play as Player 0 (Red)\n",
    "        for _ in range(games_as_p0):\n",
    "            td = env.reset()\n",
    "            done = False\n",
    "            step_count = 0\n",
    "            \n",
    "            while not done and step_count < 100:\n",
    "                current_player = int(td['observation'][0, 0, 0, 2].item())\n",
    "                \n",
    "                if current_player == 0:  # Actor's turn\n",
    "                    td = actor(td)\n",
    "                    td = env.step(td)[\"next\"]\n",
    "                    if td['done'].item() and td['reward'].item() > 0:\n",
    "                        wins_as_p0 += 1\n",
    "                else:  # Random opponent\n",
    "                    # action_mask = td['action_mask']\n",
    "                    # valid_actions = action_mask.nonzero(as_tuple=True)[0]\n",
    "                    # random_action = valid_actions[torch.randint(len(valid_actions), (1,))]\n",
    "                    # td.set('action', random_action)\n",
    "                    td = env.rand_step(td)[\"next\"]\n",
    "                \n",
    "                # td = env.step(td)[\"next\"]\n",
    "                done = td['done'].item()\n",
    "                step_count += 1\n",
    "        \n",
    "        # Play as Player 1 (Blue)\n",
    "        for _ in range(games_as_p1):\n",
    "            td = env.reset()\n",
    "            done = False\n",
    "            step_count = 0\n",
    "            \n",
    "            while not done and step_count < 100:\n",
    "                current_player = int(td['observation'][0, 0, 0, 2].item())\n",
    "                \n",
    "                if current_player == 1:  # Actor's turn\n",
    "                    td = actor(td)\n",
    "                    td = env.step(td)[\"next\"]\n",
    "                    if td['done'].item() and td['reward'].item() > 0:\n",
    "                        wins_as_p1 += 1\n",
    "                else:  # Random opponent\n",
    "                    # action_mask = td['action_mask']\n",
    "                    # valid_actions = action_mask.nonzero(as_tuple=True)[0]\n",
    "                    # random_action = valid_actions[torch.randint(len(valid_actions), (1,))]\n",
    "                    # td.set('action', random_action)\n",
    "                    td = env.rand_step(td)[\"next\"]\n",
    "                \n",
    "                # td = env.step(td)[\"next\"]\n",
    "                done = td['done'].item()\n",
    "                step_count += 1\n",
    "    \n",
    "    # actor.train()\n",
    "    \n",
    "    total_wins = wins_as_p0 + wins_as_p1\n",
    "    win_rate = total_wins / n_games\n",
    "    \n",
    "    return {\n",
    "        'win_rate': win_rate,\n",
    "        'wins_as_p0': wins_as_p0,\n",
    "        'games_as_p0': games_as_p0,\n",
    "        'wins_as_p1': wins_as_p1,\n",
    "        'games_as_p1': games_as_p1,\n",
    "        'total_wins': total_wins,\n",
    "        'total_games': n_games\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718210c",
   "metadata": {},
   "source": [
    "# Functionality Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5986ee8",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40981d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\objectives\\common.py:330: UserWarning: The name actor_network wasn't part of the annotations (dict_keys([])). Make sure it is present in the definition class.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\objectives\\common.py:330: UserWarning: The name actor_network_params wasn't part of the annotations (dict_keys([])). Make sure it is present in the definition class.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\objectives\\common.py:330: UserWarning: The name target_actor_network_params wasn't part of the annotations (dict_keys([])). Make sure it is present in the definition class.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\objectives\\common.py:330: UserWarning: The name qvalue_network wasn't part of the annotations (dict_keys([])). Make sure it is present in the definition class.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\objectives\\common.py:330: UserWarning: The name qvalue_network_params wasn't part of the annotations (dict_keys([])). Make sure it is present in the definition class.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\objectives\\common.py:330: UserWarning: The name target_qvalue_network_params wasn't part of the annotations (dict_keys([])). Make sure it is present in the definition class.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\collectors\\collectors.py:225: UserWarning: A policy device was provided but no parameter/buffer could be found in the policy. Casting to policy_device is therefore impossible. The collector will trust that the devices match. To suppress this warning, set `trust_policy=True` when building the collector.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\collectors\\collectors.py:882: UserWarning: total_frames (1000000) is not exactly divisible by frames_per_batch (128). This means 64 additional frames will be collected.To silence this message, set the environment variable RL_WARNINGS to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Tạo model gốc\n",
    "actor_model = HexModel(**MODEL_PARAMS).train().to(DEVICE) # Model cho actor\n",
    "qvalue_model = HexModel(**MODEL_PARAMS).train().to(DEVICE) # Model cho critic\n",
    "init_params(actor_model)\n",
    "init_params(qvalue_model)\n",
    "# model = HexModel(**MODEL_PARAMS).train().to(DEVICE) # Dùng chung cho cả actor và critic\n",
    "# init_params(model)\n",
    "# actor_model, qvalue_model = model, model\n",
    "\n",
    "# 2. Tạo hai wrapper và policy\n",
    "actor_network = TensorDictModule(\n",
    "    ActorWrapper(actor_model),\n",
    "    in_keys=[\"observation\", \"action_mask\"],\n",
    "    out_keys=[\"logits\", \"mask\"]\n",
    ")\n",
    "qvalue_network = TensorDictModule(\n",
    "    CriticWrapper(qvalue_model),\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action_value\"]\n",
    ")\n",
    "actor = ProbabilisticActor(\n",
    "    actor_network,\n",
    "    in_keys=[\"logits\", \"mask\"],\n",
    "    spec=serial_env.action_spec,\n",
    "    distribution_class=MaskedCategorical\n",
    ")\n",
    "\n",
    "# 3. Tạo loss_fn, optimizer, updater\n",
    "loss_fn = NegamaxDiscreteSACLoss(\n",
    "    actor_network=actor,\n",
    "    qvalue_network=qvalue_network,\n",
    "    action_space=serial_env.action_spec,\n",
    "    num_actions=serial_env.action_spec.n,\n",
    "    skip_done_states=True,\n",
    "    deactivate_vmap=True\n",
    "    # Do Transformer không hỗ trợ vmap tốt. Nếu muốn dùng vmap, cần sử dụng SDPBackend.MATH\n",
    ").to(DEVICE)\n",
    "\n",
    "## Lấy các nhóm tham số ưu tiên từ Actor và Critic (đã có config weight_decay chuẩn)\n",
    "actor_params_groups = get_optimizer_params(actor_model, WEIGHT_DECAY)\n",
    "qvalue_params_groups = get_optimizer_params(qvalue_model, WEIGHT_DECAY)\n",
    "\n",
    "## Gộp các nhóm tham số lại, ưu tiên Actor > Critic > Loss leftovers\n",
    "combined_params = merge_optimizer_params(\n",
    "    loss_fn_params=loss_fn.parameters(),\n",
    "    actor_groups=actor_params_groups,\n",
    "    qvalue_groups=qvalue_params_groups\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    params=combined_params,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY \n",
    ")\n",
    "updater = SoftUpdate(\n",
    "    loss_module=loss_fn,\n",
    "    tau=TAU\n",
    ")\n",
    "\n",
    "# 4. Thiết lập optimizer, replay buffer, và các thành phần khác như bình thường\n",
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(BUFFER_SIZE, device=STORAGE_DEVICE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "collector = SyncDataCollector(\n",
    "    create_env_fn=serial_env,\n",
    "    policy=MaskedRandomPolicy(serial_env.action_spec),\n",
    "    frames_per_batch=N_FRAMES_PER_BATCH,\n",
    "    total_frames=TOTAL_FRAMES, # Vô hạn\n",
    "    device=DEVICE,\n",
    "    storing_device=STORAGE_DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c9cf1",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f337cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Environment\n",
      "==================================================\n",
      "Reset output keys: _StringKeys(dict_keys(['terminated', 'observation', 'done', 'action_mask']))\n",
      "Observation shape: torch.Size([1, 5, 5, 5])\n",
      "Action mask shape: torch.Size([1, 25])\n",
      "Step output keys: _StringKeys(dict_keys(['terminated', 'observation', 'done', 'action_mask', 'action', 'next']))\n",
      "Reward: tensor([[0.]], device='cuda:0')\n",
      "Done: tensor([[False]], device='cuda:0')\n",
      "\n",
      "==================================================\n",
      "Testing Actor\n",
      "==================================================\n",
      "Actor output keys: _StringKeys(dict_keys(['terminated', 'observation', 'done', 'action_mask', 'logits', 'mask', 'action']))\n",
      "Action shape: torch.Size([1])\n",
      "Action value: 20\n",
      "\n",
      "==================================================\n",
      "Testing Loss Function and Backpropagation\n",
      "==================================================\n",
      "Loss keys: _StringKeys(dict_keys(['loss_actor', 'loss_qvalue', 'loss_alpha', 'alpha', 'entropy']))\n",
      "loss_actor: -3.2097\n",
      "loss_qvalue: 5.3534\n",
      "loss_alpha: 0.0000\n",
      "alpha: 1.0000\n",
      "entropy: 3.2189\n",
      "Gradient check for Actor before step:\n",
      "  Actor grad norm: 0.001991\n",
      "------------------------------\n",
      "Checking updates for Actor...\n",
      "  ✓ module.0.module.model.conv.0.adjust_input.0.conv.weight changed (diff: 0.042457)\n",
      "  ✓ module.0.module.model.conv.0.adjust_input.1.weight changed (diff: 0.002962)\n",
      "  ✓ module.0.module.model.conv.0.adjust_input.3.conv.weight changed (diff: 0.617341)\n",
      "  ✓ module.0.module.model.conv.0.adjust_input.4.weight changed (diff: 0.002886)\n",
      "  ✓ module.0.module.model.conv.0.original_input.0.weight changed (diff: 0.006098)\n",
      "  ✓ module.0.module.model.conv.0.original_input.1.weight changed (diff: 0.002709)\n",
      "  ✓ module.0.module.model.encoder.layers.0.self_attn.in_proj_weight changed (diff: 0.242450)\n",
      "  ✓ module.0.module.model.encoder.layers.0.self_attn.out_proj.weight changed (diff: 0.082000)\n",
      "  ✓ module.0.module.model.encoder.layers.0.linear1.weight changed (diff: 0.335461)\n",
      "  ✓ module.0.module.model.encoder.layers.0.linear2.weight changed (diff: 0.337983)\n",
      "  ✓ module.0.module.model.encoder.layers.0.norm1.weight changed (diff: 0.003036)\n",
      "  ✓ module.0.module.model.encoder.layers.0.norm2.weight changed (diff: 0.002944)\n",
      "  ✓ module.0.module.model.projection.weight changed (diff: 0.003200)\n",
      "  ⚠️ module.0.module.model.projection.bias did NOT change (diff: 0.0)\n",
      "✅ Actor weights updated successfully.\n",
      "Gradient check for Q-value network before step:\n",
      "  Q-Value Network grad norm: 0.000000\n",
      "Checking updates for Q-Value Network...\n",
      "  ⚠️ module.model.conv.0.adjust_input.0.conv.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.adjust_input.1.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.adjust_input.1.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.adjust_input.3.conv.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.adjust_input.4.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.adjust_input.4.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.original_input.0.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.original_input.0.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.original_input.1.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.conv.0.original_input.1.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.self_attn.in_proj_weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.self_attn.in_proj_bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.self_attn.out_proj.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.self_attn.out_proj.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.linear1.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.linear1.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.linear2.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.linear2.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.norm1.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.norm1.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.norm2.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.encoder.layers.0.norm2.bias did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.projection.weight did NOT change (diff: 0.0)\n",
      "  ⚠️ module.model.projection.bias did NOT change (diff: 0.0)\n",
      "❌ Q-Value Network weights did NOT update. Check gradients or learning rate.\n",
      "\n",
      "==================================================\n",
      "Testing Loss Backpropagation Completed\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Testing Collector\n",
      "==================================================\n",
      "Collected batch keys: _StringKeys(dict_keys(['action', 'observation', 'action_mask', 'done', 'terminated', 'next', 'collector']))\n",
      "Batch size: torch.Size([1, 128])\n",
      "Number of frames: 1\n",
      "\n",
      "==================================================\n",
      "All components working! ✓\n",
      "==================================================\n",
      "==================================================\n",
      "Testing Actor Action Validity\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results:\n",
      "Total episodes: 10\n",
      "Total steps: 1000\n",
      "Invalid actions: 0\n",
      "Invalid action rate: 0.00%\n",
      "✅ No invalid actions detected!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check for env, actor, loss, and collector\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing Environment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test environment reset and step\n",
    "test_td = serial_env.reset()\n",
    "print(f\"Reset output keys: {test_td.keys()}\")\n",
    "print(f\"Observation shape: {test_td['observation'].shape}\")\n",
    "print(f\"Action mask shape: {test_td['action_mask'].shape}\")\n",
    "\n",
    "# Take a random action\n",
    "test_td = serial_env.rand_step(test_td)\n",
    "print(f\"Step output keys: {test_td.keys()}\")\n",
    "print(f\"Reward: {test_td.get(\"next\", {}).get('reward', 'N/A')}\")\n",
    "print(f\"Done: {test_td['done']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Testing Actor\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test actor forward pass\n",
    "test_td = serial_env.reset()\n",
    "with torch.no_grad():\n",
    "    actor_output = actor(test_td)\n",
    "\n",
    "print(f\"Actor output keys: {actor_output.keys()}\")\n",
    "print(f\"Action shape: {actor_output['action'].shape}\")\n",
    "print(f\"Action value: {actor_output['action'].item()}\")\n",
    "\n",
    "# Test loss calculation with dummy data\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Testing Loss Function and Backpropagation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "actor_params_before = {name: p.clone() for name, p in actor.named_parameters()}\n",
    "# Giả sử biến mạng Q-value của bạn tên là qvalue_network hoặc critic\n",
    "# Nếu bạn dùng SAC/TD3 trong TorchRL, nó thường nằm trong loss_module hoặc là một module riêng\n",
    "# Hãy thay 'qvalue_network' bằng tên biến thực tế của bạn (ví dụ: loss_fn.qvalue_network_params hoặc critic)\n",
    "try:\n",
    "    # Ví dụ nếu bạn có biến 'qvalue_network'\n",
    "    qvalue_params_before = {name: p.clone() for name, p in qvalue_network.named_parameters()}\n",
    "    # qvalue_params_before = {name: p.clone() for name, p in loss_fn.qvalue_network_params.flatten_keys(\".\").to_dict().values()}\n",
    "except NameError:\n",
    "    print(\"⚠️ Could not find 'qvalue_network' variable to check. Skipping Q-net check.\")\n",
    "    qvalue_params_before = {name: p.clone() for name, p in loss_fn.qvalue_network_params}\n",
    "    qvalue_params_before = None\n",
    "\n",
    "test_td = serial_env.reset()\n",
    "test_td = serial_env.rand_step(test_td)\n",
    "test_batch = test_td.repeat(BATCH_SIZE).contiguous().to(DEVICE)  # Create batch\n",
    "loss_dict = loss_fn(test_batch)\n",
    "\n",
    "print(f\"Loss keys: {loss_dict.keys()}\")\n",
    "for key, value in loss_dict.items():\n",
    "    if isinstance(value, Tensor):\n",
    "        print(f\"{key}: {value.item():.4f}\")\n",
    "\n",
    "# Test loss back-propagation\n",
    "optimizer.zero_grad()\n",
    "loss = loss_dict['loss_actor'] + loss_dict['loss_alpha'] + loss_dict['loss_qvalue']\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "updater.step()\n",
    "\n",
    "print(\"Gradient check for Actor before step:\")\n",
    "total_norm = 0\n",
    "for p in actor.parameters():\n",
    "    if p.grad is not None:\n",
    "        total_norm += p.grad.data.norm(2).item()\n",
    "print(f\"  Actor grad norm: {total_norm:.6f}\")\n",
    "print(\"-\" * 30)\n",
    "check_params_changed(actor, \"Actor\", actor_params_before)\n",
    "\n",
    "print(\"Gradient check for Q-value network before step:\")\n",
    "total_norm = 0\n",
    "for p in qvalue_network.parameters():\n",
    "    if p.grad is not None:\n",
    "        total_norm += p.grad.data.norm(2).item()\n",
    "print(f\"  Q-Value Network grad norm: {total_norm:.6f}\")\n",
    "if qvalue_params_before:\n",
    "    check_params_changed(qvalue_network, \"Q-Value Network\", qvalue_params_before)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Testing Loss Backpropagation Completed\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test collector (collect a small batch)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Testing Collector\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "collector_iter = iter(collector)\n",
    "batch = next(collector_iter)\n",
    "print(f\"Collected batch keys: {batch.keys()}\")\n",
    "print(f\"Batch size: {batch.batch_size}\")\n",
    "print(f\"Number of frames: {len(batch)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"All components working! ✓\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test if actor selects invalid actions\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing Actor Action Validity\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run multiple episodes and check for invalid actions\n",
    "n_test_episodes = 10\n",
    "invalid_actions_count = 0\n",
    "total_steps = 0\n",
    "\n",
    "for episode in range(n_test_episodes):\n",
    "    test_td = serial_env.reset()\n",
    "    done = False\n",
    "    step_count = 0\n",
    "    \n",
    "    while not done and step_count < 100:  # Max 100 steps per episode\n",
    "        # Get action from actor\n",
    "        with torch.no_grad():\n",
    "            test_td = actor(test_td)\n",
    "        \n",
    "        # Extract action and action_mask\n",
    "        action = test_td['action'].item()\n",
    "        action_mask = test_td['action_mask']\n",
    "        \n",
    "        # Check if action is valid\n",
    "        is_valid = action_mask[..., action].item()\n",
    "        \n",
    "        if not is_valid:\n",
    "            invalid_actions_count += 1\n",
    "            print(f\"⚠️ Episode {episode}, Step {step_count}: Invalid action {action}\")\n",
    "            print(f\"   Action mask: {action_mask.nonzero(as_tuple=True)[0].tolist()}\")\n",
    "        \n",
    "        # Take step in environment\n",
    "        try:\n",
    "            test_td = serial_env.step(test_td)\n",
    "            done = test_td['done'].item()\n",
    "            total_steps += 1\n",
    "            step_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error at episode {episode}, step {step_count}: {e}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Results:\")\n",
    "print(f\"Total episodes: {n_test_episodes}\")\n",
    "print(f\"Total steps: {total_steps}\")\n",
    "print(f\"Invalid actions: {invalid_actions_count}\")\n",
    "print(f\"Invalid action rate: {invalid_actions_count/total_steps*100:.2f}%\")\n",
    "\n",
    "if invalid_actions_count == 0:\n",
    "    print(\"✅ No invalid actions detected!\")\n",
    "else:\n",
    "    print(\"⚠️ Invalid actions detected! Check MaskedCategorical configuration.\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8639b24",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd2262",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406d39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tạo environment như bình thường\n",
    "create_hex_env = lambda: HexEnv(board_size=BOARD_SIZE, max_board_size=MAX_BOARD_SIZE, swap_rule=SWAP_RULE, device=STORAGE_DEVICE)\n",
    "serial_env = TransformedEnv(\n",
    "    SerialEnv(\n",
    "        num_workers=1,\n",
    "        create_env_fn=create_hex_env\n",
    "    ),\n",
    "    ActionMask()\n",
    ")\n",
    "\n",
    "# 2. Tạo model gốc\n",
    "actor_model = HexModel(**MODEL_PARAMS).train().to(DEVICE) # Model cho actor\n",
    "qvalue_model = HexModel(**MODEL_PARAMS).train().to(DEVICE) # Model cho critic\n",
    "init_params(actor_model)\n",
    "init_params(qvalue_model)\n",
    "# model = HexModel(**MODEL_PARAMS).train().to(DEVICE) # Dùng chung cho cả actor và critic\n",
    "# init_params(model)\n",
    "# actor_model, qvalue_model = model, model\n",
    "\n",
    "# 3. Tạo hai wrapper và policy\n",
    "actor_network = TensorDictModule(\n",
    "    ActorWrapper(actor_model),\n",
    "    in_keys=[\"observation\", \"action_mask\"],\n",
    "    out_keys=[\"logits\", \"mask\"]\n",
    ")\n",
    "qvalue_network = TensorDictModule(\n",
    "    CriticWrapper(qvalue_model),\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action_value\"]\n",
    ")\n",
    "actor = ProbabilisticActor(\n",
    "    actor_network,\n",
    "    in_keys=[\"logits\", \"mask\"],\n",
    "    spec=serial_env.action_spec,\n",
    "    distribution_class=MaskedCategorical\n",
    ")\n",
    "\n",
    "# 4. Tạo loss_fn, optimizer, updater\n",
    "loss_fn = NegamaxDiscreteSACLoss(\n",
    "    actor_network=actor,\n",
    "    qvalue_network=qvalue_network,\n",
    "    action_space=serial_env.action_spec,\n",
    "    num_actions=serial_env.action_spec.n,\n",
    "    skip_done_states=True,\n",
    "    deactivate_vmap=True\n",
    "    # Do Transformer không hỗ trợ vmap tốt. Nếu muốn dùng vmap, cần sử dụng SDPBackend.MATH\n",
    ").to(DEVICE)\n",
    "\n",
    "## Lấy các nhóm tham số ưu tiên từ Actor và Critic (đã có config weight_decay chuẩn)\n",
    "actor_params_groups = get_optimizer_params(actor_model, WEIGHT_DECAY)\n",
    "qvalue_params_groups = get_optimizer_params(qvalue_model, WEIGHT_DECAY)\n",
    "\n",
    "## Gộp các nhóm tham số lại, ưu tiên Actor > Critic > Loss leftovers\n",
    "combined_params = merge_optimizer_params(\n",
    "    loss_fn_params=loss_fn.parameters(),\n",
    "    actor_groups=actor_params_groups,\n",
    "    qvalue_groups=qvalue_params_groups\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    params=combined_params,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY \n",
    ")\n",
    "updater = SoftUpdate(\n",
    "    loss_module=loss_fn,\n",
    "    tau=TAU\n",
    ")\n",
    "\n",
    "# 5. Thiết lập optimizer, replay buffer, và các thành phần khác như bình thường\n",
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(BUFFER_SIZE, device=STORAGE_DEVICE),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "collector = SyncDataCollector(\n",
    "    create_env_fn=serial_env,\n",
    "    policy=actor,\n",
    "    frames_per_batch=N_FRAMES_PER_BATCH,\n",
    "    total_frames=TOTAL_FRAMES, # Vô hạn\n",
    "    device=DEVICE,\n",
    "    storing_device=STORAGE_DEVICE,\n",
    "    env_device=STORAGE_DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb006156",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "478f0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "WARMUP PHASE - Random Exploration\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\collectors\\collectors.py:882: UserWarning: total_frames (5000) is not exactly divisible by frames_per_batch (128). This means 120 additional frames will be collected.To silence this message, set the environment variable RL_WARNINGS to False.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup Progress: 640/5000 frames (12.8%) | Buffer Size: 640\n",
      "Warmup Progress: 1280/5000 frames (25.6%) | Buffer Size: 1280\n",
      "Warmup Progress: 1920/5000 frames (38.4%) | Buffer Size: 1920\n",
      "Warmup Progress: 2560/5000 frames (51.2%) | Buffer Size: 2560\n",
      "Warmup Progress: 3200/5000 frames (64.0%) | Buffer Size: 3200\n",
      "Warmup Progress: 3840/5000 frames (76.8%) | Buffer Size: 3840\n",
      "Warmup Progress: 4480/5000 frames (89.6%) | Buffer Size: 4480\n",
      "Warmup Progress: 5120/5000 frames (102.4%) | Buffer Size: 5120\n",
      "\n",
      "✓ Warmup completed! Buffer size: 5120\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"WARMUP PHASE - Random Exploration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "current_frames = 0\n",
    "warmup_iterations = 0\n",
    "\n",
    "# Create a random policy for warmup\n",
    "# random_policy = lambda td: td.set('action', \n",
    "#     torch.randint(0, serial_env.action_spec.n, (1,), device=td.device))\n",
    "\n",
    "# Temporary collector for warmup\n",
    "warmup_collector = SyncDataCollector(\n",
    "    create_env_fn=serial_env,\n",
    "    policy=MaskedRandomPolicy(serial_env.action_spec),\n",
    "    frames_per_batch=N_FRAMES_PER_BATCH,\n",
    "    total_frames=WARMUP_FRAMES,\n",
    "    device=DEVICE,\n",
    "    storing_device=STORAGE_DEVICE,\n",
    "    env_device=STORAGE_DEVICE\n",
    ")\n",
    "\n",
    "for warmup_batch in warmup_collector:\n",
    "    warmup_batch = warmup_batch.reshape(-1) # Flatten batch\n",
    "    replay_buffer.extend(warmup_batch)\n",
    "    current_frames += len(warmup_batch)\n",
    "    warmup_iterations += 1\n",
    "    \n",
    "    if warmup_iterations % 5 == 0:\n",
    "        print(f\"Warmup Progress: {current_frames}/{WARMUP_FRAMES} frames \"\n",
    "              f\"({current_frames/WARMUP_FRAMES*100:.1f}%) | \"\n",
    "              f\"Buffer Size: {len(replay_buffer)}\")\n",
    "\n",
    "print(f\"\\n✓ Warmup completed! Buffer size: {len(replay_buffer)}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36ed7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MAIN TRAINING LOOP\n",
      "==================================================\n",
      "Iter 10 | Frames: 6,400 | Loss: A=-2.281 Q=3.256 α=-0.005\n",
      "Iter 20 | Frames: 7,680 | Loss: A=-1.905 Q=2.290 α=-0.011\n",
      "Iter 30 | Frames: 8,960 | Loss: A=-1.571 Q=1.386 α=-0.017\n",
      "Iter 40 | Frames: 10,240 | Loss: A=-1.299 Q=0.661 α=-0.022\n",
      "Iter 50 | Frames: 11,520 | Loss: A=-1.164 Q=0.512 α=-0.029\n",
      "Iter 60 | Frames: 12,800 | Loss: A=-1.445 Q=0.161 α=-0.036\n",
      "Iter 70 | Frames: 14,080 | Loss: A=-1.487 Q=0.089 α=-0.041\n",
      "Iter 80 | Frames: 15,360 | Loss: A=-1.536 Q=0.098 α=-0.041\n",
      "Iter 90 | Frames: 16,640 | Loss: A=-1.495 Q=0.105 α=-0.049\n",
      "\n",
      "==================================================\n",
      "Iteration 100 | Frames: 17,920/1,000,000\n",
      "==================================================\n",
      "Loss - Actor: -1.4640 | QValue: 0.0813 | Alpha: -0.0581\n",
      "WinRate: 95.0% (190/200)\n",
      "  - As P0: 99/100\n",
      "  - As P1: 91/100\n",
      "Buffer Size: 17920\n",
      "✓ New Best Model Saved! (WinRate: 95.0%)\n",
      "==================================================\n",
      "\n",
      "Iter 110 | Frames: 19,200 | Loss: A=-1.462 Q=0.123 α=-0.064\n",
      "Iter 120 | Frames: 20,480 | Loss: A=-1.507 Q=0.087 α=-0.064\n",
      "Iter 130 | Frames: 21,760 | Loss: A=-1.503 Q=0.095 α=-0.082\n",
      "Iter 140 | Frames: 23,040 | Loss: A=-1.496 Q=0.121 α=-0.085\n",
      "Iter 150 | Frames: 24,320 | Loss: A=-1.534 Q=0.121 α=-0.090\n",
      "Iter 160 | Frames: 25,600 | Loss: A=-1.502 Q=0.121 α=-0.102\n",
      "Iter 170 | Frames: 26,880 | Loss: A=-1.498 Q=0.103 α=-0.103\n",
      "Iter 180 | Frames: 28,160 | Loss: A=-1.604 Q=0.097 α=-0.101\n",
      "Iter 190 | Frames: 29,440 | Loss: A=-1.533 Q=0.105 α=-0.115\n",
      "\n",
      "==================================================\n",
      "Iteration 200 | Frames: 30,720/1,000,000\n",
      "==================================================\n",
      "Loss - Actor: -1.6281 | QValue: 0.0934 | Alpha: -0.1132\n",
      "WinRate: 98.0% (196/200)\n",
      "  - As P0: 97/100\n",
      "  - As P1: 99/100\n",
      "Buffer Size: 30720\n",
      "✓ New Best Model Saved! (WinRate: 98.0%)\n",
      "==================================================\n",
      "\n",
      "Iter 210 | Frames: 32,000 | Loss: A=-1.601 Q=0.131 α=-0.134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      8\u001b[39m best_win_rate = \u001b[32m0.0\u001b[39m\n\u001b[32m      9\u001b[39m training_history = {\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33miteration\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mactor_loss\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m'\u001b[39m: []\n\u001b[32m     16\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcollector\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# A. Add new data to replay buffer\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Flatten batch\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\collectors\\collectors.py:343\u001b[39m, in \u001b[36mDataCollectorBase.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[TensorDictBase]:\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterator()\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    345\u001b[39m         \u001b[38;5;28mself\u001b[39m.shutdown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\collectors\\collectors.py:1268\u001b[39m, in \u001b[36mSyncDataCollector.iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1267\u001b[39m     torchrl_logger.info(\u001b[33m\"\u001b[39m\u001b[33mCollector: rollout.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1268\u001b[39m tensordict_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1270\u001b[39m     \u001b[38;5;66;03m# if a replay buffer is passed and self.extend_buffer=False, there is no tensordict_out\u001b[39;00m\n\u001b[32m   1271\u001b[39m     \u001b[38;5;66;03m#  frames are updated within the rollout function\u001b[39;00m\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\_utils.py:404\u001b[39m, in \u001b[36maccept_remote_rref_invocation.<locals>.unpack_rref_and_invoke_function\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _os_is_windows \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, torch._C._distributed_rpc.PyRRef):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28mself\u001b[39m.local_value()\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\collectors\\collectors.py:1508\u001b[39m, in \u001b[36mSyncDataCollector.rollout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compiled_policy:\n\u001b[32m   1507\u001b[39m     cudagraph_mark_step_begin()\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m policy_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compiled_policy:\n\u001b[32m   1510\u001b[39m     policy_output = policy_output.clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\probabilistic.py:1364\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1360\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1361\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed while executing module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_num_or_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Scroll up for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1362\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1364\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m     tensordict_exec = \u001b[38;5;28mself\u001b[39m._last_module(\n\u001b[32m   1366\u001b[39m         tensordict_exec, _requires_sample=\u001b[38;5;28mself\u001b[39m._requires_sample\n\u001b[32m   1367\u001b[39m     )\n\u001b[32m   1369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inplace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\probabilistic.py:1116\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.get_dist_params\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not find a default interaction in the modules.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\sequence.py:633\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._module_iter():\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m         tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    637\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _has_py311_or_greater:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\sequence.py:579\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_module\u001b[39m(\n\u001b[32m    571\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    572\u001b[39m     module: TensorDictModuleBase,\n\u001b[32m    573\u001b[39m     tensordict: TensorDictBase,\n\u001b[32m    574\u001b[39m     **kwargs: Any,\n\u001b[32m    575\u001b[39m ) -> Any:\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    577\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    578\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m         tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n\u001b[32m    581\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m sub_td \u001b[38;5;129;01min\u001b[39;00m tensordict.tensordicts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:1174\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1165\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(  \u001b[38;5;66;03m# type: ignore[unreachable]\u001b[39;00m\n\u001b[32m   1166\u001b[39m         tensordict._get_tuple_maybe_non_tensor(\n\u001b[32m   1167\u001b[39m             _unravel_key_to_tuple(in_key),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_keys\n\u001b[32m   1172\u001b[39m     )\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1176\u001b[39m         tensors_out = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:1133\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m kwargs.update(\u001b[38;5;28mself\u001b[39m.method_kwargs)\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     out = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.method)(*tensors, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mActorWrapper.forward\u001b[39m\u001b[34m(self, observation, action_mask)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 1. Xác định Player 1\u001b[39;00m\n\u001b[32m     22\u001b[39m player_mask = observation[..., \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m].bool() \u001b[38;5;66;03m# Lấy kênh Current Player ở vị trí (0,0) của mỗi board trong batch (N,)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m observation = \u001b[43mobservation\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Loại bỏ kênh Current Player, giữ lại (Red, Blue, Mask, Swap) (N, H, W, 4)\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 2. Tạo input 4 kênh cho model\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m player_mask.any(): \u001b[38;5;66;03m# Có Player 1 trong batch\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MAIN TRAINING LOOP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training metrics\n",
    "iteration = 0\n",
    "total_frames_collected = current_frames\n",
    "best_win_rate = 0.0\n",
    "training_history = {\n",
    "    'iteration': [],\n",
    "    'actor_loss': [],\n",
    "    'qvalue_loss': [],\n",
    "    'alpha_loss': [],\n",
    "    'win_rate': [],\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "for batch_data in collector:\n",
    "    # A. Add new data to replay buffer\n",
    "    batch_data = batch_data.reshape(-1) # Flatten batch\n",
    "    replay_buffer.extend(batch_data)\n",
    "    total_frames_collected += len(batch_data)\n",
    "    \n",
    "    # B. Optimization loop (UTD Ratio)\n",
    "    actor_losses = []\n",
    "    qvalue_losses = []\n",
    "    alpha_losses = []\n",
    "    \n",
    "    for opt_step in range(OPTIMIZATION_STEPS):\n",
    "        # B1. Sample batch\n",
    "        sample = replay_buffer.sample(BATCH_SIZE)\n",
    "        sample = sample.to(DEVICE)\n",
    "        \n",
    "        # B2. Compute losses\n",
    "        loss_dict = loss_fn(sample)\n",
    "        \n",
    "        total_loss = (loss_dict['loss_actor'] + \n",
    "                     loss_dict['loss_qvalue'] + \n",
    "                     loss_dict['loss_alpha'])\n",
    "        \n",
    "        # B3. Gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(actor.parameters()) + list(qvalue_network.parameters()), \n",
    "            max_norm=1.0\n",
    "        )\n",
    "        optimizer.step()\n",
    "        \n",
    "        # B4. Soft update target network\n",
    "        updater.step()\n",
    "        \n",
    "        # Collect losses\n",
    "        actor_losses.append(loss_dict['loss_actor'].item())\n",
    "        qvalue_losses.append(loss_dict['loss_qvalue'].item())\n",
    "        alpha_losses.append(loss_dict['loss_alpha'].item())\n",
    "    \n",
    "    # C. Logging and evaluation\n",
    "    iteration += 1\n",
    "    avg_actor_loss = sum(actor_losses) / len(actor_losses)\n",
    "    avg_qvalue_loss = sum(qvalue_losses) / len(qvalue_losses)\n",
    "    avg_alpha_loss = sum(alpha_losses) / len(alpha_losses)\n",
    "    \n",
    "    # Store metrics\n",
    "    training_history['iteration'].append(iteration)\n",
    "    training_history['actor_loss'].append(avg_actor_loss)\n",
    "    training_history['qvalue_loss'].append(avg_qvalue_loss)\n",
    "    training_history['alpha_loss'].append(avg_alpha_loss)\n",
    "    training_history['frames'].append(total_frames_collected)\n",
    "    \n",
    "    # Periodic evaluation\n",
    "    if iteration % LOG_INTERVAL == 0:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Iteration {iteration} | Frames: {total_frames_collected:,}/{TOTAL_FRAMES:,}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Evaluate agent\n",
    "        actor.eval()\n",
    "        eval_results = evaluate_agent(actor, serial_env, n_games=EVAL_GAMES, device=DEVICE)\n",
    "        actor.train()\n",
    "        win_rate = eval_results['win_rate']\n",
    "        training_history['win_rate'].append(win_rate)\n",
    "        \n",
    "        print(f\"Loss - Actor: {avg_actor_loss:.4f} | QValue: {avg_qvalue_loss:.4f} | Alpha: {avg_alpha_loss:.4f}\")\n",
    "        print(f\"WinRate: {win_rate:.1%} ({eval_results['total_wins']}/{eval_results['total_games']})\")\n",
    "        print(f\"  - As P0: {eval_results['wins_as_p0']}/{eval_results['games_as_p0']}\")\n",
    "        print(f\"  - As P1: {eval_results['wins_as_p1']}/{eval_results['games_as_p1']}\")\n",
    "        print(f\"Buffer Size: {len(replay_buffer)}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if win_rate > best_win_rate:\n",
    "            best_win_rate = win_rate\n",
    "            # torch.save({\n",
    "            #     'iteration': iteration,\n",
    "            #     'actor_state_dict': actor_model.state_dict(),\n",
    "            #     'qvalue_state_dict': qvalue_model.state_dict(),\n",
    "            #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #     'win_rate': win_rate,\n",
    "            #     'training_history': training_history\n",
    "            # }, f'd:/Code/Python/hex-irl/checkpoints/hex_{BOARD_SIZE}x{BOARD_SIZE}_best.pth')\n",
    "            print(f\"✓ New Best Model Saved! (WinRate: {best_win_rate:.1%})\")\n",
    "        \n",
    "        print(f\"{'='*50}\\n\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if best_win_rate > 0.98:\n",
    "            print(\"🎉 Target win rate achieved! Stopping training.\")\n",
    "            break\n",
    "    else:\n",
    "        # Brief progress update\n",
    "        if iteration % int(torch.sqrt(torch.tensor(LOG_INTERVAL)).item()) == 0:\n",
    "            print(f\"Iter {iteration} | Frames: {total_frames_collected:,} | \"\n",
    "                  f\"Loss: A={avg_actor_loss:.3f} Q={avg_qvalue_loss:.3f} α={avg_alpha_loss:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(f\"Best Win Rate: {best_win_rate:.1%}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460ce9c",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51537327",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Win Rate\u001b[39;00m\n\u001b[32m     28\u001b[39m eval_iterations = [training_history[\u001b[33m'\u001b[39m\u001b[33miteration\u001b[39m\u001b[33m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(training_history[\u001b[33m'\u001b[39m\u001b[33miteration\u001b[39m\u001b[33m'\u001b[39m]), LOG_INTERVAL)]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_history\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwin_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m axes[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m].axhline(y=\u001b[32m0.5\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, linestyle=\u001b[33m'\u001b[39m\u001b[33m--\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mRandom Baseline\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m axes[\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m].set_title(\u001b[33m'\u001b[39m\u001b[33mWin Rate vs Random Policy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programs\\miniconda3\\envs\\hex\\Lib\\site-packages\\matplotlib\\axes\\_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (3,) and (2,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Actor Loss\n",
    "axes[0, 0].plot(training_history['iteration'], training_history['actor_loss'])\n",
    "axes[0, 0].set_title('Actor Loss')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# QValue Loss\n",
    "axes[0, 1].plot(training_history['iteration'], training_history['qvalue_loss'])\n",
    "axes[0, 1].set_title('Q-Value Loss')\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Alpha Loss\n",
    "axes[1, 0].plot(training_history['iteration'], training_history['alpha_loss'])\n",
    "axes[1, 0].set_title('Alpha Loss (Temperature)')\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Win Rate\n",
    "eval_iterations = [training_history['iteration'][i] for i in range(0, len(training_history['iteration']), LOG_INTERVAL)]\n",
    "axes[1, 1].plot(eval_iterations, training_history['win_rate'], marker='o')\n",
    "axes[1, 1].axhline(y=0.5, color='r', linestyle='--', label='Random Baseline')\n",
    "axes[1, 1].set_title('Win Rate vs Random Policy')\n",
    "axes[1, 1].set_xlabel('Iteration')\n",
    "axes[1, 1].set_ylabel('Win Rate')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'd:/Code/Python/hex-irl/results/training_curves_{BOARD_SIZE}x{BOARD_SIZE}.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Training curves saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FINAL EVALUATION - 100 Games\n",
      "==================================================\n",
      "\n",
      "Final Results:\n",
      "  Total Win Rate: 94.0%\n",
      "  Wins as Player 0 (Red): 48/50 (96.0%)\n",
      "  Wins as Player 1 (Blue): 46/50 (92.0%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"FINAL EVALUATION - 100 Games\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_eval = evaluate_agent(actor, serial_env, n_games=100, device=DEVICE)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Total Win Rate: {final_eval['win_rate']:.1%}\")\n",
    "print(f\"  Wins as Player 0 (Red): {final_eval['wins_as_p0']}/{final_eval['games_as_p0']} \"\n",
    "      f\"({final_eval['wins_as_p0']/final_eval['games_as_p0']:.1%})\")\n",
    "print(f\"  Wins as Player 1 (Blue): {final_eval['wins_as_p1']}/{final_eval['games_as_p1']} \"\n",
    "      f\"({final_eval['wins_as_p1']/final_eval['games_as_p1']:.1%})\")\n",
    "# print(f\"\\nBest Win Rate During Training: {best_win_rate:.1%}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Checking Actor Parameters Validity\n",
      "============================================================\n",
      "✓ module.0.module.model.conv.0.adjust_input.0.conv.weight: Valid - min=-0.681706, max=0.801933\n",
      "✓ module.0.module.model.conv.0.adjust_input.1.weight: Valid - min=0.942665, max=1.063240\n",
      "✓ module.0.module.model.conv.0.adjust_input.1.bias: Valid - min=-0.018415, max=0.055370\n",
      "✓ module.0.module.model.conv.0.adjust_input.3.conv.weight: Valid - min=-0.295153, max=0.350219\n",
      "✓ module.0.module.model.conv.0.adjust_input.4.weight: Valid - min=0.909890, max=1.042353\n",
      "✓ module.0.module.model.conv.0.adjust_input.4.bias: Valid - min=-0.038754, max=0.021844\n",
      "✓ module.0.module.model.conv.0.original_input.0.weight: Valid - min=-0.647249, max=0.604259\n",
      "✓ module.0.module.model.conv.0.original_input.0.bias: Valid - min=-0.031745, max=0.048193\n",
      "✓ module.0.module.model.conv.0.original_input.1.weight: Valid - min=0.953714, max=1.070481\n",
      "✓ module.0.module.model.conv.0.original_input.1.bias: Valid - min=-0.038754, max=0.021844\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.in_proj_weight: Valid - min=-0.289497, max=0.278724\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.in_proj_bias: Valid - min=-0.070577, max=0.070228\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.out_proj.weight: Valid - min=-0.774632, max=0.783845\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.out_proj.bias: Valid - min=-0.023662, max=0.022824\n",
      "✓ module.0.module.model.encoder.layers.0.linear1.weight: Valid - min=-0.405888, max=0.435026\n",
      "✓ module.0.module.model.encoder.layers.0.linear1.bias: Valid - min=-0.060398, max=0.047548\n",
      "✓ module.0.module.model.encoder.layers.0.linear2.weight: Valid - min=-0.412587, max=0.434947\n",
      "✓ module.0.module.model.encoder.layers.0.linear2.bias: Valid - min=-0.060059, max=0.066411\n",
      "✓ module.0.module.model.encoder.layers.0.norm1.weight: Valid - min=0.957306, max=1.046501\n",
      "✓ module.0.module.model.encoder.layers.0.norm1.bias: Valid - min=-0.061617, max=0.061918\n",
      "✓ module.0.module.model.encoder.layers.0.norm2.weight: Valid - min=0.951180, max=1.049092\n",
      "✓ module.0.module.model.encoder.layers.0.norm2.bias: Valid - min=-0.000041, max=0.000023\n",
      "✓ module.0.module.model.projection.weight: Valid - min=-0.042261, max=0.049319\n",
      "✓ module.0.module.model.projection.bias: Valid - min=0.000081, max=0.000081\n",
      "\n",
      "============================================================\n",
      "Summary:\n",
      "  Total parameters: 24\n",
      "  Valid parameters: 24\n",
      "  Parameters with NaN: 0\n",
      "  Parameters with Inf: 0\n",
      "\n",
      "✅ All actor parameters are valid!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_actor_params_validity(actor):\n",
    "    \"\"\"\n",
    "    Check if actor parameters contain valid real numbers (not NaN or Inf).\n",
    "    \n",
    "    Returns:\n",
    "        dict with detailed information about parameter validity\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'all_valid': True,\n",
    "        'total_params': 0,\n",
    "        'nan_params': [],\n",
    "        'inf_params': [],\n",
    "        'valid_params': 0\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Checking Actor Parameters Validity\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, param in actor.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            results['total_params'] += 1\n",
    "            \n",
    "            # Check for NaN\n",
    "            has_nan = torch.isnan(param).any().item()\n",
    "            # Check for Inf\n",
    "            has_inf = torch.isinf(param).any().item()\n",
    "            \n",
    "            if has_nan:\n",
    "                results['all_valid'] = False\n",
    "                results['nan_params'].append(name)\n",
    "                print(f\"❌ {name}: Contains NaN values\")\n",
    "                print(f\"   Shape: {param.shape}, NaN count: {torch.isnan(param).sum().item()}\")\n",
    "            \n",
    "            if has_inf:\n",
    "                results['all_valid'] = False\n",
    "                results['inf_params'].append(name)\n",
    "                print(f\"❌ {name}: Contains Inf values\")\n",
    "                print(f\"   Shape: {param.shape}, Inf count: {torch.isinf(param).sum().item()}\")\n",
    "            \n",
    "            if not has_nan and not has_inf:\n",
    "                results['valid_params'] += 1\n",
    "                # Optional: print min/max for valid params\n",
    "                print(f\"✓ {name}: Valid - min={param.min().item():.6f}, max={param.max().item():.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary:\")\n",
    "    print(f\"  Total parameters: {results['total_params']}\")\n",
    "    print(f\"  Valid parameters: {results['valid_params']}\")\n",
    "    print(f\"  Parameters with NaN: {len(results['nan_params'])}\")\n",
    "    print(f\"  Parameters with Inf: {len(results['inf_params'])}\")\n",
    "    \n",
    "    if results['all_valid']:\n",
    "        print(\"\\n✅ All actor parameters are valid!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Some actor parameters contain invalid values!\")\n",
    "        if results['nan_params']:\n",
    "            print(f\"\\nNaN in: {results['nan_params']}\")\n",
    "        if results['inf_params']:\n",
    "            print(f\"\\nInf in: {results['inf_params']}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the check\n",
    "validity_results = check_actor_params_validity(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c44cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All actor parameters have been set to zeros\n",
      "\n",
      "Verifying parameters are zeros:\n",
      "✓ module.0.module.model.conv.0.adjust_input.0.conv.weight: All zeros\n",
      "✓ module.0.module.model.conv.0.adjust_input.1.weight: All zeros\n",
      "✓ module.0.module.model.conv.0.adjust_input.1.bias: All zeros\n",
      "✓ module.0.module.model.conv.0.adjust_input.3.conv.weight: All zeros\n",
      "✓ module.0.module.model.conv.0.adjust_input.4.weight: All zeros\n",
      "✓ module.0.module.model.conv.0.adjust_input.4.bias: All zeros\n",
      "✓ module.0.module.model.conv.0.original_input.0.weight: All zeros\n",
      "✓ module.0.module.model.conv.0.original_input.0.bias: All zeros\n",
      "✓ module.0.module.model.conv.0.original_input.1.weight: All zeros\n",
      "✓ module.0.module.model.conv.0.original_input.1.bias: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.in_proj_weight: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.in_proj_bias: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.out_proj.weight: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.self_attn.out_proj.bias: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.linear1.weight: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.linear1.bias: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.linear2.weight: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.linear2.bias: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.norm1.weight: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.norm1.bias: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.norm2.weight: All zeros\n",
      "✓ module.0.module.model.encoder.layers.0.norm2.bias: All zeros\n",
      "✓ module.0.module.model.projection.weight: All zeros\n",
      "✓ module.0.module.model.projection.bias: All zeros\n",
      "\n",
      "✅ All actor parameters are successfully set to zeros!\n"
     ]
    }
   ],
   "source": [
    "# Set all actor parameters to zero\n",
    "with torch.no_grad():\n",
    "    for param in actor.parameters():\n",
    "        param.zero_()\n",
    "\n",
    "print(\"✓ All actor parameters have been set to zeros\")\n",
    "\n",
    "# Verify the change\n",
    "print(\"\\nVerifying parameters are zeros:\")\n",
    "all_zeros = True\n",
    "for name, param in actor.named_parameters():\n",
    "    if param.abs().sum().item() > 0:\n",
    "        all_zeros = False\n",
    "        print(f\"❌ {name}: NOT zero (sum of abs values: {param.abs().sum().item()})\")\n",
    "    else:\n",
    "        print(f\"✓ {name}: All zeros\")\n",
    "\n",
    "if all_zeros:\n",
    "    print(\"\\n✅ All actor parameters are successfully set to zeros!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some parameters are not zeros!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
