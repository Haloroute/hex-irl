{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4262247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchrl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torch import Tensor\n",
    "from torchrl.envs import EnvBase, SerialEnv\n",
    "from torchrl.data import (\n",
    "    Binary,\n",
    "    Bounded,\n",
    "    Categorical,\n",
    "    Composite,\n",
    "    TensorSpec,\n",
    "    UnboundedContinuous\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b431a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "board_size = 5 # Size of the Hex board (board_size x board_size)\n",
    "N_CHANNEL = 4 # Number of channels for the observation (Red, Blue, Current Player, Valid Board)\n",
    "MAX_BOARD_SIZE = 32 # Maximum board size for the Hex game\n",
    "SWAP_RULE = False # Whether to use the swap rule in the Hex game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7bfea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445067485"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HexEnv(EnvBase):\n",
    "    def __init__(self, \n",
    "                 board_size: int,\n",
    "                 max_board_size: int = MAX_BOARD_SIZE,\n",
    "                #  swap_rule: bool = SWAP_RULE,\n",
    "                 device: torch.device = 'cpu',\n",
    "                #  batch_size: torch.Size = torch.Size()\n",
    "                ):\n",
    "\n",
    "        # Assertions\n",
    "        assert board_size >= 1, \"Board size must be greater than or equal to 1.\"\n",
    "        assert board_size <= max_board_size, \"Board size must be less than or equal to max Board size.\"\n",
    "\n",
    "        super().__init__(device=device, spec_locked=False)\n",
    "\n",
    "        # Parameters\n",
    "        self.board_size: int = board_size\n",
    "        self.max_board_size: int = max_board_size\n",
    "        self.n_channel: int = N_CHANNEL\n",
    "        # self.swap_rule: bool = swap_rule # Not implemented yet\n",
    "        # self.device: torch.device = device\n",
    "        # self.batch_size: torch.Size = batch_size # No batching at all\n",
    "\n",
    "        # Create shape variables\n",
    "        self.board_shape: torch.Size = torch.Size(\n",
    "            (self.max_board_size, self.max_board_size)\n",
    "        ) # (max_board_size, max_board_size)\n",
    "\n",
    "        # Valid board mask\n",
    "        self.valid_board: Tensor = torch.zeros(\n",
    "            self.board_shape, \n",
    "            dtype=torch.bool, \n",
    "            device=self.device\n",
    "        ) # (max_board_size, max_board_size)\n",
    "        self.valid_board[:self.board_size, :self.board_size] = 1\n",
    "\n",
    "        # Create private spec variables\n",
    "        self.observation_spec = Composite({\n",
    "            \"observation\": Binary(\n",
    "                shape=self.board_shape + (self.n_channel,),\n",
    "                # (max_board_size, max_board_size, n_channel)\n",
    "                device=self.device,\n",
    "                dtype=torch.float32\n",
    "            ),\n",
    "            \"mask\": Binary(\n",
    "                shape=self.board_shape,\n",
    "                # (max_board_size, max_board_size)\n",
    "                device=self.device,\n",
    "                dtype=torch.bool\n",
    "            )\n",
    "        })\n",
    "        self.action_spec = Categorical(\n",
    "            n=self.max_board_size ** 2,\n",
    "            # Number of discrete actions for each side of the board\n",
    "            shape=(1,),\n",
    "            # (1,) because action is a scalar representing the flat index of the board\n",
    "            device=self.device,\n",
    "            dtype=torch.long,\n",
    "            mask=(self.valid_board.flatten() == 1) # (max_board_size ** 2)\n",
    "        )\n",
    "        self.reward_spec = UnboundedContinuous(\n",
    "            shape=(1,),\n",
    "            device=device,\n",
    "            dtype=torch.float32\n",
    "        ) # Reward for both players\n",
    "\n",
    "    def _reset(self, tensordict: TensorDict | None = None, **kwargs) -> TensorDict:\n",
    "        # Initialize a fresh board\n",
    "        board: Tensor = torch.full((self.max_board_size, self.max_board_size), -1, dtype=torch.long) # -1: empty, 0: player 0 (red), 1: player 1 (blue)\n",
    "        # current_player: int = 0 # 0: player 0 (red), 1: player 1 (blue)\n",
    "        # valid_move: Tensor = self.valid_board.float() # All valid moves at the start\n",
    "        done: Tensor = torch.tensor(False, dtype=torch.bool) # Game not done\n",
    "        reward: Tensor = torch.tensor([0.0], dtype=torch.float32) # No reward at the start\n",
    "\n",
    "        # Create fresh observation, mask, done, reward\n",
    "        fresh_action: Tensor = torch.tensor([0], dtype=torch.long) # Placeholder action\n",
    "        fresh_observation: Tensor = torch.zeros((self.max_board_size, self.max_board_size, self.n_channel), dtype=torch.float32) # (max_board_size, max_board_size, n_channel)\n",
    "        fresh_observation[..., 0] = (board == 0).float() # Red pieces channel\n",
    "        fresh_observation[..., 1] = (board == 1).float() # Blue pieces channel\n",
    "        fresh_observation[..., 2] = 0 # 0: player 0 (red), 1: player 1 (blue)\n",
    "        fresh_observation[..., -1] = self.valid_board.clone().float() # (max_board_size, max_board_size) Playable board mask\n",
    "        fresh_mask: Tensor = self.valid_board.clone().bool() # (max_board_size ** 2) Valid move mask\n",
    "        fresh_done: Tensor = done # Not done\n",
    "        fresh_reward: Tensor = reward # No reward at the start\n",
    "\n",
    "        # Update action spec for the environment\n",
    "        self.action_spec.update_mask(fresh_mask.flatten())\n",
    "\n",
    "        # Update tensordict\n",
    "        fresh_tensordict = TensorDict({\n",
    "            \"action\": fresh_action,\n",
    "            \"observation\": fresh_observation,\n",
    "            \"mask\": fresh_mask,\n",
    "            \"done\": fresh_done,\n",
    "            \"reward\": fresh_reward\n",
    "        })\n",
    "\n",
    "        return fresh_tensordict\n",
    "\n",
    "    def _step(self, tensordict: TensorDict, **kwargs) -> TensorDict:\n",
    "        # Extract action\n",
    "        action: Tensor = tensordict.get(\"action\").clone() # Scalar tensor representing the action\n",
    "        observation: Tensor = tensordict.get(\"observation\").clone() # (max_board_size, max_board_size, n_channel)\n",
    "        mask: Tensor = tensordict.get(\"mask\").clone() # (max_board_size, max_board_size)\n",
    "        done: Tensor = tensordict.get(\"done\").clone() # Scalar tensor representing if the game is done\n",
    "        reward: Tensor = tensordict.get(\"reward\").clone() # (2,)\n",
    "\n",
    "        # Extract indexes of action from observation\n",
    "        index: int = int(action.item())\n",
    "        row, col = divmod(index, self.max_board_size) # Convert flat index to 2D coordinates\n",
    "\n",
    "        # Extract current state from observation\n",
    "        current_player: int = int(observation[..., 0, 0, 2].item()) # 0: player 0 (red), 1: player 1 (blue)\n",
    "\n",
    "        # Validate action\n",
    "        is_valid = (\n",
    "            0 <= row < self.max_board_size and # Must be within board's max bounds\n",
    "            0 <= col < self.max_board_size and # Must be within board's max bounds\n",
    "            self.valid_board[row, col] and # Must be in valid board area\n",
    "            mask[row, col] == 1  # Must be empty to place a piece\n",
    "        )\n",
    "\n",
    "        # If action is not valid (only when action_spec mask is not working properly)\n",
    "        if not is_valid:\n",
    "            raise ValueError(f\"Invalid action {action.item()} at row={row}; col={col}; valid={self.valid_board[row, col]}, mask={mask[row, col]}.\")\n",
    "            # reward[self.current_player - 1] = -1.0 # Penalty for invalid move\n",
    "            # self.done = False # Continue the game even if the move is invalid\n",
    "            # new_observation, new_mask = tensordict.get(\"observation\"), tensordict.get(\"mask\") # Keep previous observation and mask\n",
    "        else:\n",
    "            # Place the piece\n",
    "            observation[row, col, current_player] = 1.0 # Update observation for the current player\n",
    "            mask[row, col] = 0 # Update mask to prevent placing another piece here\n",
    "\n",
    "            # Check for win condition (placeholder logic)\n",
    "            if self._check_done(observation, current_player):\n",
    "                reward: Tensor = torch.tensor([1.0 * (1 - current_player) - 1.0 * current_player], dtype=torch.float32, device=self.device) # Single reward for the current player (+1 if player 0 wins, -1 if player 1 wins)\n",
    "                done = torch.tensor(True, dtype=torch.bool) # Game done\n",
    "            else:\n",
    "                reward: Tensor = torch.tensor([0.0], dtype=torch.float32, device=self.device) # Initialize reward\n",
    "                done = torch.tensor(False, dtype=torch.bool) # Game not done\n",
    "\n",
    "                # Switch player\n",
    "                current_player = 1 - current_player # Switch between 0 and 1\n",
    "\n",
    "            # Update observation, mask\n",
    "            new_observation: Tensor = torch.zeros((self.max_board_size, self.max_board_size, self.n_channel), dtype=torch.float) # (max_board_size, max_board_size, n_channel)\n",
    "            new_observation[..., 0] = observation[..., 0] # Red pieces channel\n",
    "            new_observation[..., 1] = observation[..., 1] # Blue pieces channel\n",
    "            new_observation[..., 2] = float(current_player) # Current player channel\n",
    "            new_observation[..., -1] = observation[..., -1] # (max_board_size, max_board_size) Playable board mask (doesn't change)\n",
    "            new_mask: Tensor = mask.bool() # Valid move mask\n",
    "\n",
    "        # Create done, reward tensors\n",
    "        new_action: Tensor = action\n",
    "        new_done: Tensor = done\n",
    "        new_reward: Tensor = reward\n",
    "\n",
    "        # Update action spec for the environment\n",
    "        self.action_spec.update_mask(new_mask.flatten())\n",
    "\n",
    "        # Update tensordict\n",
    "        new_tensordict = TensorDict({\n",
    "            \"action\": new_action,\n",
    "            \"observation\": new_observation,\n",
    "            \"mask\": new_mask,\n",
    "            \"done\": new_done,\n",
    "            \"reward\": new_reward\n",
    "        })\n",
    "\n",
    "        return new_tensordict\n",
    "\n",
    "    def _check_done(self, observation: Tensor, current_player: int) -> bool:\n",
    "        def dfs(board, start_positions, target_condition, directions):\n",
    "            visited = torch.zeros((self.board_size, self.board_size), dtype=torch.bool)\n",
    "            for start in start_positions:\n",
    "                if board[start] == 1 and not visited[start]:\n",
    "                    stack = [start]\n",
    "                    visited[start] = True\n",
    "                    while stack:\n",
    "                        r, c = stack.pop()\n",
    "                        if target_condition(r, c):\n",
    "                            return True\n",
    "                        for dr, dc in directions:\n",
    "                            nr, nc = r + dr, c + dc\n",
    "                            if 0 <= nr < self.board_size and 0 <= nc < self.board_size and board[nr, nc] == 1 and not visited[nr, nc]:\n",
    "                                visited[nr, nc] = True\n",
    "                                stack.append((nr, nc))\n",
    "            return False\n",
    "\n",
    "        directions = [(-1,0), (1,0), (0,-1), (0,1), (1,-1), (-1,1)] # 6 possible directions in a hex grid\n",
    "        # Use DFS to check if player 0 (red) has connected top to bottom\n",
    "        if current_player == 0:\n",
    "            board = (observation[..., 0] == 1)[..., :self.board_size, :self.board_size] # Player 0 pieces\n",
    "            start_positions = [(0, col) for col in range(self.board_size)]\n",
    "            target_condition = lambda r, c: r == self.board_size - 1\n",
    "            if dfs(board, start_positions, target_condition, directions):\n",
    "                return True\n",
    "\n",
    "        # Use DFS to check if player 1 (blue) has connected left to right\n",
    "        else:\n",
    "            board = (observation[..., 1] == 1)[..., :self.board_size, :self.board_size] # Player 1 pieces\n",
    "            start_positions = [(row, 0) for row in range(self.board_size)]\n",
    "            target_condition = lambda r, c: c == self.board_size - 1\n",
    "            if dfs(board, start_positions, target_condition, directions):\n",
    "                return True\n",
    "\n",
    "        return False # No winner yet\n",
    "\n",
    "    def _set_seed(self, seed: int) -> None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "env = HexEnv(board_size=board_size, max_board_size=MAX_BOARD_SIZE, device=device)\n",
    "env.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095fa5f",
   "metadata": {},
   "source": [
    "# Use rand_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b6b5a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "EnvBase.forward is not implemented. If you ended here during a call to `ParallelEnv(...)`, please use a constructor such as `ParallelEnv(num_env, lambda env=env: env)` instead. Batched envs require constructors because environment instances may not always be serializable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m create_env_fn = HexEnv(board_size=board_size, max_board_size=MAX_BOARD_SIZE, device=device)\n\u001b[32m      3\u001b[39m serial_env = SerialEnv(\n\u001b[32m      4\u001b[39m     num_workers=\u001b[32m1\u001b[39m,\n\u001b[32m      5\u001b[39m     create_env_fn=create_env_fn\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m state = \u001b[43mserial_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m step = \u001b[32m1\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# The loop condition remains the same\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:2859\u001b[39m, in \u001b[36mEnvBase.reset\u001b[39m\u001b[34m(self, tensordict, **kwargs)\u001b[39m\n\u001b[32m   2855\u001b[39m     tensordict_reset = \u001b[38;5;28mself\u001b[39m._reset(\n\u001b[32m   2856\u001b[39m         tensordict.select(*\u001b[38;5;28mself\u001b[39m.reset_keys, strict=\u001b[38;5;28;01mFalse\u001b[39;00m), **kwargs\n\u001b[32m   2857\u001b[39m     )\n\u001b[32m   2858\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2859\u001b[39m     tensordict_reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2860\u001b[39m \u001b[38;5;66;03m# We assume that this is done properly\u001b[39;00m\n\u001b[32m   2861\u001b[39m \u001b[38;5;66;03m# if reset.device != self.device:\u001b[39;00m\n\u001b[32m   2862\u001b[39m \u001b[38;5;66;03m#     reset = reset.to(self.device, non_blocking=True)\u001b[39;00m\n\u001b[32m   2863\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_reset \u001b[38;5;129;01mis\u001b[39;00m tensordict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\batched_envs.py:68\u001b[39m, in \u001b[36m_check_start.<locals>.decorated_fun\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_closed:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_td()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ParallelEnv):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\batched_envs.py:938\u001b[39m, in \u001b[36mSerialEnv._start_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    936\u001b[39m weakref_set = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(_num_workers):\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m     env = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_env_fn\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_env_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m     \u001b[38;5;66;03m# We want to avoid having the same env multiple times\u001b[39;00m\n\u001b[32m    940\u001b[39m     \u001b[38;5;66;03m# so we try to deepcopy it if needed. If we can't, we make\u001b[39;00m\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# the user aware that this isn't a very good idea\u001b[39;00m\n\u001b[32m    942\u001b[39m     wr = weakref.ref(env)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:2805\u001b[39m, in \u001b[36mEnvBase.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m2805\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   2806\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEnvBase.forward is not implemented. If you ended here during a call to `ParallelEnv(...)`, please use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2807\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33ma constructor such as `ParallelEnv(num_env, lambda env=env: env)` instead. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2808\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBatched envs require constructors because environment instances may not always be serializable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2809\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: EnvBase.forward is not implemented. If you ended here during a call to `ParallelEnv(...)`, please use a constructor such as `ParallelEnv(num_env, lambda env=env: env)` instead. Batched envs require constructors because environment instances may not always be serializable."
     ]
    }
   ],
   "source": [
    "# Reset the environment once at the beginning\n",
    "create_env_fn = HexEnv(board_size=board_size, max_board_size=MAX_BOARD_SIZE, device=device)\n",
    "serial_env = SerialEnv(\n",
    "    num_workers=1,\n",
    "    create_env_fn=create_env_fn\n",
    ")\n",
    "state = serial_env.reset()\n",
    "step = 1\n",
    "\n",
    "# The loop condition remains the same\n",
    "while not state.get(\"done\").any(): # Using .any() is safer for batched envs\n",
    "    # A single call to rand_step() performs a random action and advances the state.\n",
    "    # It returns a TensorDict with the full transition data.\n",
    "    transition_data = serial_env.rand_step(state)\n",
    "\n",
    "    # Extract information for printing from the results\n",
    "    action = transition_data.get(\"action\")\n",
    "    current_observation = transition_data.get(\"observation\")\n",
    "    current_mask = transition_data.get(\"mask\")\n",
    "    current_done = transition_data.get(\"done\")\n",
    "    next_state = transition_data.get(\"next\")\n",
    "\n",
    "    reward = next_state.get(\"reward\")\n",
    "    next_observation = next_state.get(\"observation\")\n",
    "    next_mask = next_state.get(\"mask\")\n",
    "    next_done = next_state.get(\"done\")\n",
    "\n",
    "    # The printing logic is the same\n",
    "    x, y = divmod(action.item(), env.max_board_size)\n",
    "    print(\n",
    "        f\"STEP: {step}. \\n\"\n",
    "        f\"Current State: \"\n",
    "        f\"Player: {current_observation[..., 2].mean().item():.0f}. \"\n",
    "        f\"Sum: {current_observation.sum().item():.0f}. \"\n",
    "        f\"Remained: {current_mask.sum().item():.0f}. \"\n",
    "        f\"{'Done: True. ' if current_done.item() else ''}\\n\"\n",
    "        f\"Action: {x}-{y}. \\n\"\n",
    "        f\"Next State: \"\n",
    "        f\"Player: {next_observation[..., 2].mean().item():.0f}. \"\n",
    "        f\"Sum: {next_observation.sum().item():.0f}. \"\n",
    "        f\"Remained: {next_mask.sum().item():.0f}. \"\n",
    "        f\"{'Done: True. ' if next_done.item() else ''}\\n\"\n",
    "        f\"Reward: {reward.item()} \\n\"\n",
    "    )\n",
    "    \n",
    "    # IMPORTANT: Update the state for the next loop iteration\n",
    "    step += 1\n",
    "    state = next_state.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b862d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: 1. Action: 4-0. Observation Sum: 1050. Remained: 24. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 3-4. Observation Sum: 27. Remained: 23. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 3-0. Observation Sum: 1052. Remained: 22. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 4-1. Observation Sum: 29. Remained: 21. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 0-1. Observation Sum: 1054. Remained: 20. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 2-3. Observation Sum: 31. Remained: 19. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 1-4. Observation Sum: 1056. Remained: 18. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 4-4. Observation Sum: 33. Remained: 17. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 1-2. Observation Sum: 1058. Remained: 16. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 2-4. Observation Sum: 35. Remained: 15. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 2-0. Observation Sum: 1060. Remained: 14. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 2-1. Observation Sum: 37. Remained: 13. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 0-3. Observation Sum: 1062. Remained: 12. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 4-3. Observation Sum: 39. Remained: 11. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 1-1. Observation Sum: 40. Remained: 10. Done: True. Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment once at the beginning\n",
    "state = env.reset()\n",
    "\n",
    "# The loop condition remains the same\n",
    "while not state.get(\"done\").any(): # Using .any() is safer for batched envs\n",
    "    # A single call to rand_step() performs a random action and advances the state.\n",
    "    # It returns a TensorDict with the full transition data.\n",
    "    transition_data = env.rand_step(state)\n",
    "\n",
    "    # Extract information for printing from the results\n",
    "    action = transition_data.get(\"action\")\n",
    "    next_state = transition_data.get(\"next\")\n",
    "    \n",
    "    observation = next_state.get(\"observation\")\n",
    "    mask = next_state.get(\"mask\")\n",
    "    reward = next_state.get(\"reward\")\n",
    "    done = next_state.get(\"done\")\n",
    "\n",
    "    # The printing logic is the same\n",
    "    x, y = divmod(action.item(), env.max_board_size)\n",
    "    print(\n",
    "        f\"Player: {observation[..., 2].mean().item():.0f}. \"\n",
    "        f\"Action: {x}-{y}. \"\n",
    "        f\"Observation Sum: {observation.sum().item():.0f}. \"\n",
    "        f\"Remained: {mask.sum().item():.0f}. \"\n",
    "        f\"Done: {done.item()}. \"\n",
    "        f\"Reward: {reward.item()}\"\n",
    "    )\n",
    "    \n",
    "    # IMPORTANT: Update the state for the next loop iteration\n",
    "    state = next_state.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574b5ad",
   "metadata": {},
   "source": [
    "# Use rand_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03857f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: 1. Action: 4-4. Observation Sum: 1050. Remained: 24. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 3-2. Observation Sum: 27. Remained: 23. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 2-2. Observation Sum: 1052. Remained: 22. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 1-0. Observation Sum: 29. Remained: 21. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 0-4. Observation Sum: 1054. Remained: 20. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 0-2. Observation Sum: 31. Remained: 19. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 3-1. Observation Sum: 1056. Remained: 18. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 0-0. Observation Sum: 33. Remained: 17. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 1-4. Observation Sum: 1058. Remained: 16. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 2-3. Observation Sum: 35. Remained: 15. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 2-0. Observation Sum: 1060. Remained: 14. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 4-3. Observation Sum: 37. Remained: 13. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 1-1. Observation Sum: 1062. Remained: 12. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 1-3. Observation Sum: 39. Remained: 11. Done: False. Reward: 0.0\n",
      "Player: 1. Action: 3-4. Observation Sum: 1064. Remained: 10. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 3-3. Observation Sum: 41. Remained: 9. Done: False. Reward: 0.0\n",
      "Player: 0. Action: 2-4. Observation Sum: 42. Remained: 8. Done: True. Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Giả sử 'env' đã được khởi tạo\n",
    "state = env.reset()\n",
    "done = state.get(\"done\")\n",
    "\n",
    "while not done.any():\n",
    "    # Thực hiện một bước ngẫu nhiên.\n",
    "    # 'transition_data' giờ chứa toàn bộ (S, A, R, S')\n",
    "    transition_data = env.rand_step(state)\n",
    "\n",
    "    # Lấy thông tin từ transition để in ra\n",
    "    action = transition_data.get(\"action\")\n",
    "    next_state = transition_data.get(\"next\") # Lấy ra state kết quả\n",
    "\n",
    "    observation = next_state.get(\"observation\")\n",
    "    mask = next_state.get(\"mask\")\n",
    "    reward = next_state.get(\"reward\")\n",
    "    done = next_state.get(\"done\")\n",
    "\n",
    "    # In thông tin\n",
    "    x, y = divmod(action.item(), env.max_board_size)\n",
    "    print(\n",
    "        f\"Player: {observation[..., 2].mean().item():.0f}. \"\n",
    "        f\"Action: {x}-{y}. \"\n",
    "        f\"Observation Sum: {observation.sum().item():.0f}. \"\n",
    "        f\"Remained: {mask.sum().item():.0f}. \"\n",
    "        f\"Done: {done.item()}. \"\n",
    "        f\"Reward: {reward.item()}\"\n",
    "    )\n",
    "\n",
    "    # !!! ĐÂY LÀ DÒNG QUAN TRỌNG NHẤT !!!\n",
    "    # Cập nhật state hiện tại để chuẩn bị cho vòng lặp tiếp theo.\n",
    "    # .clone() là một thói quen tốt để tránh các lỗi tham chiếu.\n",
    "    state = next_state.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e82bc",
   "metadata": {},
   "source": [
    "# Use rollout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e357bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'clone'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# env.rollout() handles the reset internally, so you don't need to call it.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# It collects data for a maximum of 50 steps.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rollout_data = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# The 'rollout_data' now contains the entire history of the episode.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Its shape will be [batch_size, num_steps]. For a single environment, this is [1, T].\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# We can squeeze the batch dimension and iterate through the steps to print them.\u001b[39;00m\n\u001b[32m      8\u001b[39m episode_data = rollout_data.squeeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:3384\u001b[39m, in \u001b[36mEnvBase.rollout\u001b[39m\u001b[34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[39m\n\u001b[32m   3378\u001b[39m     tensordicts = \u001b[38;5;28mself\u001b[39m._rollout_stop_early(\n\u001b[32m   3379\u001b[39m         break_when_all_done=break_when_all_done,\n\u001b[32m   3380\u001b[39m         break_when_any_done=break_when_any_done,\n\u001b[32m   3381\u001b[39m         **kwargs,\n\u001b[32m   3382\u001b[39m     )\n\u001b[32m   3383\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3384\u001b[39m     tensordicts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rollout_nonstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3385\u001b[39m batch_size = \u001b[38;5;28mself\u001b[39m.batch_size \u001b[38;5;28;01mif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensordict.batch_size\n\u001b[32m   3386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:3616\u001b[39m, in \u001b[36mEnvBase._rollout_nonstop\u001b[39m\u001b[34m(self, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[39m\n\u001b[32m   3614\u001b[39m     tensordict = \u001b[38;5;28mself\u001b[39m.step(tensordict_)\n\u001b[32m   3615\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3616\u001b[39m     tensordict, tensordict_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_and_maybe_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3617\u001b[39m tensordicts.append(tensordict)\n\u001b[32m   3618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == max_steps - \u001b[32m1\u001b[39m:\n\u001b[32m   3619\u001b[39m     \u001b[38;5;66;03m# we don't truncate as one could potentially continue the run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:3670\u001b[39m, in \u001b[36mEnvBase.step_and_maybe_reset\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   3668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict.device != \u001b[38;5;28mself\u001b[39m.device:\n\u001b[32m   3669\u001b[39m     tensordict = tensordict.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m3670\u001b[39m tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3671\u001b[39m \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[32m   3672\u001b[39m \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[32m   3673\u001b[39m tensordict_ = \u001b[38;5;28mself\u001b[39m._step_mdp(tensordict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:2102\u001b[39m, in \u001b[36mEnvBase.step\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   2099\u001b[39m next_preset = tensordict.get(\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m     next_tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2103\u001b[39m     next_tensordict = \u001b[38;5;28mself\u001b[39m._step_proc_data(next_tensordict)\n\u001b[32m   2104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2105\u001b[39m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[32m   2106\u001b[39m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[32m   2107\u001b[39m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mHexEnv._step\u001b[39m\u001b[34m(self, tensordict, **kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m mask: Tensor = tensordict.get(\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m).clone() \u001b[38;5;66;03m# (max_board_size, max_board_size)\u001b[39;00m\n\u001b[32m    105\u001b[39m done: Tensor = tensordict.get(\u001b[33m\"\u001b[39m\u001b[33mdone\u001b[39m\u001b[33m\"\u001b[39m).clone() \u001b[38;5;66;03m# Scalar tensor representing if the game is done\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m reward: Tensor = \u001b[43mtensordict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m() \u001b[38;5;66;03m# (2,)\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Extract indexes of action from observation\u001b[39;00m\n\u001b[32m    109\u001b[39m index: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28mint\u001b[39m(action.item())\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'clone'"
     ]
    }
   ],
   "source": [
    "# env.rollout() handles the reset internally, so you don't need to call it.\n",
    "# It collects data for a maximum of 50 steps.\n",
    "rollout_data = env.rollout(max_steps=50, break_when_any_done=False)\n",
    "\n",
    "# The 'rollout_data' now contains the entire history of the episode.\n",
    "# Its shape will be [batch_size, num_steps]. For a single environment, this is [1, T].\n",
    "# We can squeeze the batch dimension and iterate through the steps to print them.\n",
    "episode_data = rollout_data.squeeze(0)\n",
    "\n",
    "print(\"--- Rollout Results ---\")\n",
    "for i in range(episode_data.shape[0]):\n",
    "    # Get the data for the i-th step from the recorded history\n",
    "    step_data = episode_data[i]\n",
    "    \n",
    "    action = step_data.get(\"action\")\n",
    "    next_state = step_data.get(\"next\")\n",
    "    \n",
    "    observation = next_state.get(\"observation\")\n",
    "    mask = next_state.get(\"mask\")\n",
    "    reward = next_state.get(\"reward\")\n",
    "    done = next_state.get(\"done\")\n",
    "\n",
    "    # The printing logic is the same as before\n",
    "    x, y = divmod(action.item(), env.max_board_size)\n",
    "    print(\n",
    "        f\"{i + 1:02d}. \"\n",
    "        f\"Player: {observation[..., 2].mean().item():.0f}. \"\n",
    "        f\"Action: {x}-{y}. \"\n",
    "        f\"Remained: {mask.sum().item():.0f}. \"\n",
    "        f\"Done: {done.item()}. \"\n",
    "        f\"Reward: {reward.item()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ae57e",
   "metadata": {},
   "source": [
    "# Multi-Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822f2b6",
   "metadata": {},
   "source": [
    "# DQN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class HexConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(HexConv2d, self).__init__()\n",
    "        assert kernel_size % 2 == 1 and kernel_size > 0, \"kernel_size must be odd and positive.\"\n",
    "        stride, padding = 1, kernel_size // 2  # To maintain spatial dimensions\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.mask = nn.Parameter(self._create_hex_mask(kernel_size), requires_grad=False) # (k, k), requires_grad=False to keep it fixed\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight.mul_(self.mask)  # Apply mask to weights\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_hex_mask(kernel_size: int) -> Tensor:\n",
    "        assert kernel_size % 2 == 1 and kernel_size > 0, \"kernel_size must be odd and positive.\"\n",
    "\n",
    "        mask = torch.zeros((kernel_size, kernel_size), dtype=torch.float32)\n",
    "        center = kernel_size // 2\n",
    "\n",
    "        for r in range(kernel_size): # Row index\n",
    "            for c in range(kernel_size): # Column index\n",
    "                # Using axial distance for a vertically oriented hex grid\n",
    "                # mapped to an offset coordinate system in the kernel.\n",
    "                # (r, c) are kernel indices, (dr, dc) are relative to center.\n",
    "                dr, dc = r - center, c - center\n",
    "                chebyshev_distance = max(abs(dr), abs(dc), abs(dr + dc))\n",
    "\n",
    "                if chebyshev_distance <= center: # Inside or on the hexagon\n",
    "                    mask[r, c] = 1.0\n",
    "\n",
    "        return mask # (kernel_size, kernel_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # Assuming x is of shape (batch_size, channels, height, width)\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SkipConnection(nn.Module):\n",
    "    def __init__(self, adjust_input: nn.Module, original_input: nn.Module = nn.Identity()):\n",
    "        super(SkipConnection, self).__init__()\n",
    "        self.adjust_input = adjust_input\n",
    "        self.original_input = original_input\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.adjust_input(x) + self.original_input(x)\n",
    "\n",
    "\n",
    "class TransformerQL(nn.Module):\n",
    "    def __init__(self, \n",
    "                 conv_layers: list[tuple[int, int]],\n",
    "                 n_encoder_layers: int,\n",
    "                 d_input: int,\n",
    "                 n_heads: int = 8,\n",
    "                 d_ff: int = 2048,\n",
    "                 dropout: float = 0.1,\n",
    "                 output_flatten: bool = True):\n",
    "        \"\"\"Args:\n",
    "            conv_layers: List of tuples (out_channels, kernel_size) for each conv layer.\n",
    "                Note that, in_channels is inferred from the previous layer's out_channels (d_input for the first layer).\n",
    "            n_encoder_layers: Number of transformer encoder layers.\n",
    "            d_input: Dimension of input features to the transformer.\n",
    "            n_heads: Number of attention heads in the transformer.\n",
    "            d_ff: Dimension of the feedforward network in the transformer.\n",
    "            dropout: Dropout rate.\n",
    "        \"\"\"\n",
    "        super(TransformerQL, self).__init__()\n",
    "        self.output_flatten = output_flatten\n",
    "        self.d_encoder: int = conv_layers[-1][0] # Last conv layer's out_channels as d_model\n",
    "        self.conv = nn.Sequential(*[\n",
    "            SkipConnection(\n",
    "                nn.Sequential(\n",
    "                    HexConv2d(conv_layers[i-1][0] if i > 0 else d_input, conv_layers[i][0], conv_layers[i][1]),\n",
    "                    nn.BatchNorm2d(conv_layers[i][0]),\n",
    "                    nn.GELU(),\n",
    "                    HexConv2d(conv_layers[i][0], conv_layers[i][0], conv_layers[i][1]),\n",
    "                    nn.BatchNorm2d(conv_layers[i][0]),\n",
    "                ),\n",
    "                nn.Identity() if conv_layers[i][0] == conv_layers[i-1][0] # Skip connection (identity)\n",
    "                else HexConv2d(conv_layers[i-1][0] if i > 0 else d_input, conv_layers[i][0], 1) # Combine with Conv2d (kernel_size = 1) for channel adjustment\n",
    "            )\n",
    "            for i in range(len(conv_layers))\n",
    "        ])\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=self.d_encoder,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=d_ff,\n",
    "                dropout=dropout,\n",
    "                activation='gelu',\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=n_encoder_layers\n",
    "        )\n",
    "        self.projection = nn.Linear(self.d_encoder, 1)\n",
    "\n",
    "    def forward(self, x: Tensor, tensordict: TensorDict | None = None) -> Tensor:\n",
    "        \"\"\"Args:\n",
    "            x: Input tensor of shape (N, H, W, C) where\n",
    "               N = batch size, H = height, W = width, C = channels (d_input).\n",
    "            Returns: Tensor of shape (N, H, W) with Q-values for each position.\n",
    "        \"\"\"\n",
    "        # Reshape input to (N, C, H, W) for Conv2d\n",
    "        batch_size, height, width = x.size(0), x.size(1), x.size(2)\n",
    "        x = x.cuda() if torch.cuda.is_available() else x.cpu()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous() # (N, C, H, W)\n",
    "        x = self.conv(x) # (N, d_encoder, H, W)\n",
    "        # Reshape to (N, H*W, d_encoder)\n",
    "        x = x.view(batch_size, -1, self.d_encoder) # (N, H*W, d_encoder)\n",
    "        x = self.encoder(x) # (N, H*W, d_encoder)\n",
    "        x = self.projection(x) # (N, H*W, 1)\n",
    "        if self.output_flatten:\n",
    "            return x.view(batch_size, -1) # (N, H*W)\n",
    "        else:\n",
    "            return x.view(batch_size, height, width) # (N, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731454aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom policy for Hex that wraps a DQN.\n",
    "    - If it's Player 0's turn, it maximizes the Q-value.\n",
    "    - If it's Player 1's turn, it minimizes the Q-value.\n",
    "    It always respects the action mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, dqn_network: nn.Module):\n",
    "        super().__init__()\n",
    "        self.dqn_network = dqn_network\n",
    "\n",
    "    def forward(self, x: Tensor, tensordict: TensorDict | None = None) -> Tensor:\n",
    "        # x: (N, H, W, C)\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0) # Add batch dimension if missing\n",
    "        batch_size = x.size(0)\n",
    "        # Step 1: Get the raw Q-values from your network\n",
    "        mask = ~(x[..., 0].bool() | x[..., 1].bool() | ~x[..., -1].bool()).view(batch_size, -1) # Assuming mask is the sum of red and blue channels\n",
    "        q_values: Tensor = self.dqn_network(x) # (N, num_actions)\n",
    "\n",
    "        # Step 2: Determine the current player and adjust Q-values accordingly.\n",
    "        # We assume the 3rd channel (index 2) of the observation indicates the player.\n",
    "        # Player 0: channel is all 0s. Player 1: channel is all 1s.\n",
    "        current_player: float = x[..., 2].mean().item() # Will be 0.0 or 1.0\n",
    "\n",
    "        if current_player == 1.0:\n",
    "            # Player 1 (blue) wants to MINIMIZE the Q-value.\n",
    "            # This is equivalent to MAXIMIZING the negative Q-value.\n",
    "            effective_q_values = -q_values\n",
    "        else:\n",
    "            # Player 0 (red) wants to MAXIMIZE the Q-value.\n",
    "            effective_q_values = q_values\n",
    "\n",
    "        # Step 3: Apply the action mask. This is crucial.\n",
    "        # Set the Q-value of all illegal moves to negative infinity.\n",
    "        effective_q_values[~mask] = -torch.inf\n",
    "\n",
    "        return effective_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state keys: _StringKeys(dict_keys(['action', 'observation', 'mask', 'done', 'reward', 'terminated']))\n",
      "Mask sum (valid moves): 25\n",
      "Board size: 5x5\n",
      "\n",
      "Result keys: _StringKeys(dict_keys(['action', 'observation', 'mask', 'done', 'reward', 'terminated', 'action_value', 'chosen_action_value']))\n",
      "\n",
      "Chosen action: 32 -> Position (1, 0)\n",
      "Chosen action value: 0.7713963985443115\n",
      "Is valid move: True\n",
      "\n",
      "Q-values shape: torch.Size([1, 1024])\n",
      "Q-values range: [-inf, 0.7714]\n"
     ]
    }
   ],
   "source": [
    "model = TransformerQL(\n",
    "    conv_layers=[(32, 3), (64, 3), (128, 3), (256, 3)],\n",
    "    n_encoder_layers=8,\n",
    "    d_input=N_CHANNEL,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    dropout=0.1,\n",
    "    output_flatten=True\n",
    ").to(device)\n",
    "test_state = env.reset().to(device).unsqueeze(0) # Add batch dimension\n",
    "\n",
    "print(f\"Initial state keys: {test_state.keys()}\")\n",
    "print(f\"Mask sum (valid moves): {test_state.get('mask').sum().item()}\")\n",
    "print(f\"Board size: {board_size}x{board_size}\")\n",
    "\n",
    "from torchrl.modules import QValueActor\n",
    "\n",
    "# This actor takes observations and an action_mask,\n",
    "# feeds the observation to the model,\n",
    "# applies the mask to the resulting Q-values,\n",
    "# and then outputs the best valid action.\n",
    "policy = TurnWrapper(model).to(device)\n",
    "policy_actor = QValueActor(\n",
    "    module=policy,\n",
    "    in_keys=[\"observation\"], # CRUCIAL: Tell the actor to use the mask\n",
    "    spec=env.action_spec\n",
    ")\n",
    "with torch.no_grad():\n",
    "    result = policy_actor(test_state)\n",
    "\n",
    "print(f\"\\nResult keys: {result.keys()}\")\n",
    "action = result.get(\"action\")\n",
    "chosen_value = result.get(\"chosen_action_value\")\n",
    "\n",
    "if action is not None:\n",
    "    action_idx = action.item()\n",
    "    row, col = divmod(action_idx, env.max_board_size)\n",
    "    print(f\"\\nChosen action: {action_idx} -> Position ({row}, {col})\")\n",
    "    print(f\"Chosen action value: {chosen_value.item() if chosen_value is not None else 'N/A'}\")\n",
    "    print(f\"Is valid move: {test_state.get('mask')[..., row, col].item()}\")\n",
    "else:\n",
    "    print(\"No action returned!\")\n",
    "\n",
    "# Optional: Check all Q-values\n",
    "if \"action_value\" in result.keys():\n",
    "    q_values = result.get(\"action_value\")\n",
    "    print(f\"\\nQ-values shape: {q_values.shape}\")\n",
    "    print(f\"Q-values range: [{q_values.min().item():.4f}, {q_values.max().item():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8c2f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but got weight is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA___slow_conv2d_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    TurnWrapper(\n      (dqn_network): TransformerQL(\n        (conv): Sequential(\n          (0): SkipConnection(\n            (adjust_input): Sequential(\n              (0): HexConv2d(\n                (conv): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): GELU(approximate='none')\n              (3): HexConv2d(\n                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (original_input): HexConv2d(\n              (conv): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))\n            )\n          )\n          (1): SkipConnection(\n            (adjust_input): Sequential(\n              (0): HexConv2d(\n                (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): GELU(approximate='none')\n              (3): HexConv2d(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (original_input): HexConv2d(\n              (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n            )\n          )\n          (2): SkipConnection(\n            (adjust_input): Sequential(\n              (0): HexConv2d(\n                (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): GELU(approximate='none')\n              (3): HexConv2d(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (original_input): HexConv2d(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n            )\n          )\n          (3): SkipConnection(\n            (adjust_input): Sequential(\n              (0): HexConv2d(\n                (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): GELU(approximate='none')\n              (3): HexConv2d(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              )\n              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (original_input): HexConv2d(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n            )\n          )\n        )\n        (encoder): TransformerEncoder(\n          (layers): ModuleList(\n            (0-7): 8 x TransformerEncoderLayer(\n              (self_attn): MultiheadAttention(\n                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n              )\n              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n              (dropout1): Dropout(p=0.1, inplace=False)\n              (dropout2): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (projection): Linear(in_features=256, out_features=1, bias=True)\n      )\n    )\n    in_keys=['observation']\n    out_keys=['action_value'].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# env.rollout() handles the reset internally, so you don't need to call it.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# It collects data for a maximum of 50 steps.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rollout_data = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# The 'rollout_data' now contains the entire history of the episode.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Its shape will be [batch_size, num_steps]. For a single environment, this is [1, T].\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# We can squeeze the batch dimension and iterate through the steps to print them.\u001b[39;00m\n\u001b[32m      8\u001b[39m episode_data = rollout_data.squeeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:3384\u001b[39m, in \u001b[36mEnvBase.rollout\u001b[39m\u001b[34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[39m\n\u001b[32m   3378\u001b[39m     tensordicts = \u001b[38;5;28mself\u001b[39m._rollout_stop_early(\n\u001b[32m   3379\u001b[39m         break_when_all_done=break_when_all_done,\n\u001b[32m   3380\u001b[39m         break_when_any_done=break_when_any_done,\n\u001b[32m   3381\u001b[39m         **kwargs,\n\u001b[32m   3382\u001b[39m     )\n\u001b[32m   3383\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3384\u001b[39m     tensordicts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rollout_nonstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3385\u001b[39m batch_size = \u001b[38;5;28mself\u001b[39m.batch_size \u001b[38;5;28;01mif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensordict.batch_size\n\u001b[32m   3386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torchrl\\envs\\common.py:3606\u001b[39m, in \u001b[36mEnvBase._rollout_nonstop\u001b[39m\u001b[34m(self, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[39m\n\u001b[32m   3604\u001b[39m         tensordict_.clear_device_()\n\u001b[32m   3605\u001b[39m \u001b[38;5;66;03m# In case policy(..) does not modify in-place - no-op for TensorDict and related\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3606\u001b[39m tensordict_.update(\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   3607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_cast_to_device:\n\u001b[32m   3608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m env_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\sequence.py:633\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._module_iter():\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m         tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    637\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _has_py311_or_greater:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\sequence.py:579\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_module\u001b[39m(\n\u001b[32m    571\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    572\u001b[39m     module: TensorDictModuleBase,\n\u001b[32m    573\u001b[39m     tensordict: TensorDictBase,\n\u001b[32m    574\u001b[39m     **kwargs: Any,\n\u001b[32m    575\u001b[39m ) -> Any:\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    577\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    578\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m         tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n\u001b[32m    581\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m sub_td \u001b[38;5;129;01min\u001b[39;00m tensordict.tensordicts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:1218\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1216\u001b[39m in_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1217\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1220\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:1190\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSome tensors that are necessary for the module call may \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1186\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot have not been found in the input tensordict: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1188\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1192\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1193\u001b[39m ):\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:1174\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1165\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(  \u001b[38;5;66;03m# type: ignore[unreachable]\u001b[39;00m\n\u001b[32m   1166\u001b[39m         tensordict._get_tuple_maybe_non_tensor(\n\u001b[32m   1167\u001b[39m             _unravel_key_to_tuple(in_key),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_keys\n\u001b[32m   1172\u001b[39m     )\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1176\u001b[39m         tensors_out = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\tensordict\\nn\\common.py:1133\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m kwargs.update(\u001b[38;5;28mself\u001b[39m.method_kwargs)\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     out = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.method)(*tensors, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mTurnWrapper.forward\u001b[39m\u001b[34m(self, x, tensordict)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Step 1: Get the raw Q-values from your network\u001b[39;00m\n\u001b[32m     18\u001b[39m mask = ~(x[..., \u001b[32m0\u001b[39m].bool() | x[..., \u001b[32m1\u001b[39m].bool() | ~x[..., -\u001b[32m1\u001b[39m].bool()).view(batch_size, -\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# Assuming mask is the sum of red and blue channels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m q_values: Tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdqn_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (N, num_actions)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Step 2: Determine the current player and adjust Q-values accordingly.\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# We assume the 3rd channel (index 2) of the observation indicates the player.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Player 0: channel is all 0s. Player 1: channel is all 1s.\u001b[39;00m\n\u001b[32m     24\u001b[39m current_player: \u001b[38;5;28mfloat\u001b[39m = x[..., \u001b[32m2\u001b[39m].mean().item() \u001b[38;5;66;03m# Will be 0.0 or 1.0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mTransformerQL.forward\u001b[39m\u001b[34m(self, x, tensordict)\u001b[39m\n\u001b[32m    111\u001b[39m batch_size, height, width = x.size(\u001b[32m0\u001b[39m), x.size(\u001b[32m1\u001b[39m), x.size(\u001b[32m2\u001b[39m)\n\u001b[32m    112\u001b[39m x = x.permute(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous() \u001b[38;5;66;03m# (N, C, H, W)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (N, d_encoder, H, W)\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Reshape to (N, H*W, d_encoder)\u001b[39;00m\n\u001b[32m    115\u001b[39m x = x.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.d_encoder) \u001b[38;5;66;03m# (N, H*W, d_encoder)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mSkipConnection.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madjust_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.original_input(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mHexConv2d.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# Assuming x is of shape (batch_size, channels, height, width)\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Apply convolution\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\hex\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but got weight is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA___slow_conv2d_forward)",
      "Failed while executing module '0'."
     ]
    }
   ],
   "source": [
    "# env.rollout() handles the reset internally, so you don't need to call it.\n",
    "# It collects data for a maximum of 50 steps.\n",
    "rollout_data = env.rollout(max_steps=50, policy=policy_actor, break_when_any_done=False)\n",
    "\n",
    "# The 'rollout_data' now contains the entire history of the episode.\n",
    "# Its shape will be [batch_size, num_steps]. For a single environment, this is [1, T].\n",
    "# We can squeeze the batch dimension and iterate through the steps to print them.\n",
    "episode_data = rollout_data.squeeze(0)\n",
    "\n",
    "print(\"--- Rollout Results ---\")\n",
    "for i in range(episode_data.shape[0]):\n",
    "    # Get the data for the i-th step from the recorded history\n",
    "    step_data = episode_data[i]\n",
    "    \n",
    "    action = step_data.get(\"action\")\n",
    "    next_state = step_data.get(\"next\")\n",
    "    \n",
    "    observation = next_state.get(\"observation\")\n",
    "    mask = next_state.get(\"mask\")\n",
    "    reward = next_state.get(\"reward\")\n",
    "    done = next_state.get(\"done\")\n",
    "\n",
    "    # The printing logic is the same as before\n",
    "    x, y = divmod(action.item(), env.max_board_size)\n",
    "    print(\n",
    "        f\"{i + 1:02d}. \"\n",
    "        f\"Player: {observation[..., 2].mean().item():.0f}. \"\n",
    "        f\"Action: {x}-{y}. \"\n",
    "        f\"Remained: {mask.sum().item():.0f}. \"\n",
    "        f\"Done: {done.item()}. \"\n",
    "        f\"Reward: {reward.item()}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
